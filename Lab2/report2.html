<head>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>
</head>

<h1 id="relat-rio-laborat-rio-1">Relatório Laboratório 2 - Calibração de Câmeras</h1>
<p>Jorge Luiz Pinto Junior  - RA: 11058715 - CEO</p>
<p>Marcos Baldrigue Andrade - RA: 11201921777 - CFO - Financeiro</p>
<p>Guilherme Eduardo Pereira - RA: 11201720498 - CPO - Desenvolvimento</p>
<p>Data de realização do experimento: 25/06/2025</p>
<p>Data de publicação do relatório: 02/07/2025</p>
<h2 id="introdu-o">Introdução</h2>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
Este laboratório experimental tem como objetivo proporcionar aos alunos a compreensão dos conceitos fundamentais relacionados aos parâmetros intrínsecos e extrínsecos de câmeras, por meio da realização de um experimento prático de calibração. A atividade é dividida em quatro etapas sequenciais. Na primeira (Etapa A), realiza-se a calibração de uma câmera utilizando imagens fornecidas previamente, com o auxílio do programa L2_cal.py. Em seguida (Etapa B), os alunos geram suas próprias imagens com auxílio do programa L2_chess.py, capturando um padrão de tabuleiro de xadrez em diferentes orientações, e as utilizam para uma nova calibração com o L2_cal.py. Na terceira fase (Etapa C), o mesmo procedimento é repetido com uma segunda câmera, que apresenta maior distorção óptica. Por fim (Etapa D), os alunos produzem imagens adicionais com essa segunda câmera, com o objetivo de aplicar a correção de distorções previamente identificadas. 
</p> 

<h2 id="procedimentos-experimentais">Procedimentos Experimentais</h2>

<h3 id="-a-leitura-de-imagem-em-arquivo">(A) Calibração de câmera com imagens fornecidas.</h3>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
O programa abaixo (L2_cal.py) executa o processo de calibração de câmeras e tem por resultado os seguintes parâmetros: a matriz <strong>K</strong>, o vetor <strong>R</strong> , o vetor <strong>d</strong> e o vetor <strong>t</strong>. Estes parâmetros são explicados em detalhes na sessão de <strong>Análise dos Resultados</strong>. A execução correta do programa exige que o mesmo esteja dentro da pasta contendo as imagens que serão utilizadas para a calibração, nesta mesma pasta foi aberto o terminal do linux para execução do programa.
</p> 

<pre>
<code class="language-python">
import cv2
import numpy as np
import os
import glob

# Defining the dimensions of checkerboard
CHECKERBOARD = (6,9)
criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)

# Creating vector to store vectors of 3D points for each checkerboard image
objpoints = []
# Creating vector to store vectors of 2D points for each checkerboard image
imgpoints = [] 

# Defining the world coordinates for 3D points
objp = np.zeros((1, CHECKERBOARD[0] * CHECKERBOARD[1], 3), np.float32)
objp[0,:,:2] = np.mgrid[0:CHECKERBOARD[0], 0:CHECKERBOARD[1]].T.reshape(-1, 2)

# Extracting path of individual image stored in a given directory
images = glob.glob('*.jpg')
for fname in images:
    img = cv2.imread(fname)
    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
    ret, corners = cv2.findChessboardCorners(
        gray, CHECKERBOARD, 
        cv2.CALIB_CB_ADAPTIVE_THRESH + 
        cv2.CALIB_CB_FAST_CHECK + 
        cv2.CALIB_CB_NORMALIZE_IMAGE)
    
    if ret == True:
        objpoints.append(objp)
        corners2 = cv2.cornerSubPix(gray, corners, (11,11), (-1,-1), criteria)
        imgpoints.append(corners2)
        img = cv2.drawChessboardCorners(img, CHECKERBOARD, corners2, ret)
    
    cv2.imshow('img', img)
    cv2.waitKey(0)

cv2.destroyAllWindows()

h, w = img.shape[:2]

ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(
    objpoints, imgpoints, gray.shape[::-1], None, None)

print("Camera matrix : \n", mtx)
print("dist : \n", dist)
print("rvecs : \n", rvecs)
print("tvecs : \n", tvecs)
</code>
</pre>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  A seguir são mostradas as imagens utilizadas para calibrar a câmera. As imagens processadas pelo programa são mostradas na sessão <strong>Análise dos Resultados</strong>.
</p>

<div style="display: flex; justify-content: center; gap: 1px;">
  <img src="/Lab2/samples/left01.jpg" alt="letf01" width="200" height=" 100">
  <img src="/Lab2/samples/left02.jpg" alt="letf02" width="200" height=" 100">
  <img src="/Lab2/samples/left03.jpg" alt="letf03" width="200" height=" 100">
  <img src="/Lab2/samples/left04.jpg" alt="letf04" width="200" height=" 100">
  <img src="/Lab2/samples/left05.jpg" alt="letf05" width="200" height=" 100">
  <img src="/Lab2/samples/left06.jpg" alt="letf06" width="200" height=" 100">
  <img src="/Lab2/samples/left07.jpg" alt="letf07" width="200" height=" 100">
</div>

<div style="display: flex; justify-content: center; gap: 1px;">
  <img src="/Lab2/samples/left08.jpg" alt="letf08" width="200" height=" 100">
  <img src="/Lab2/samples/left09.jpg" alt="letf09" width="200" height=" 100">
  <img src="/Lab2/samples/left11.jpg" alt="letf11" width="200" height=" 100">
  <img src="/Lab2/samples/left12.jpg" alt="letf12" width="200" height=" 100">
  <img src="/Lab2/samples/left13.jpg" alt="letf13" width="200" height=" 100">
  <img src="/Lab2/samples/left14.jpg" alt="letf14" width="200" height=" 100">
</div>

<div style="display: flex; justify-content: center">
  <figcaption>Figura 1 - Samples.</figcaption>
</div>


<h3 id="-b-leitura-de-v-deo-em-arquivo">(B) Calibração da sua webcam com a captura de suas próprias imagens.</h3>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  As imagens a seguir foram geradas pelo grupo e utilizadas pelo programa L2_cal.py para calibrar a câmera novamente (mesma câmera da parte A). Um ajuste no programa se fez necessário, pois, o tabuleiro utilizado nas imagens de amostra tem tamanho de 6x9, enquanto que o tabuleiro utilizado no laboratório tem tamanho 6x8, a seguir a trecho modificado do programa (dimensões do tabuleiro):
</p>

<div style="display: flex; justify-content: center; gap: 1px;">
  <img src="/Lab2/Nossas_imagens/Ajuste_Programa.jpg" alt="letf01" width="600" height=" 200">
</div>

  <div style="display: flex; justify-content: center">
    <figcaption>Figura X - Ajuste no programa L2_cal.py.</figcaption>
  </div>

<div style="display: flex; justify-content: center; gap: 1px;">
  <img src="/Lab2/Nossas_imagens/Jorge0.jpg" alt="letf01" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens/Jorge1.jpg" alt="letf02" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens/Jorge2.jpg" alt="letf03" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens/Jorge3.jpg" alt="letf04" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens/Jorge4.jpg" alt="letf05" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens/Jorge5.jpg" alt="letf06" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens/Jorge6.jpg" alt="letf07" width="200" height=" 100">
</div>

<div style="display: flex; justify-content: center; gap: 1px;">
  <img src="/Lab2/Nossas_imagens/Jorge7.jpg" alt="letf08" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens/Jorge8.jpg" alt="letf09" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens/Jorge9.jpg" alt="letf11" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens/Jorge11.jpg" alt="letf12" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens/Jorge13.jpg" alt="letf13" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens/Jorge14.jpg" alt="letf14" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens/Jorge15.jpg" alt="letf14" width="200" height=" 100">
</div>

<div style="display: flex; justify-content: center">
  <figcaption>Figura X - Imagens geradas pelo grupo.</figcaption>
</div>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  O resultado do processamento das imagens se encontra na sessão <strong>Análise dos Resultados</strong>.
</p>

<h3 id="-c-leitura-de-imagem-de-c-mera">(C) Calibração de outra câmera do laboratório</h3>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
 Para realização da parte C, foi utilizada outra câmera fornecida no laboratório, esta possui distorção de imagem superior do que a câmera utilizada nas partes A e B. As imagens utilizadas para calibração são as mesmas da parte B. Os resultados são apresentados na sessão <strong>Análise dos Resultados</strong>. A seguir são apresentadas as imagens geradas através do programa L2_chess.py:
</p>

<div style="display: flex; justify-content: center; gap: 1px;">
  <img src="/Lab2/Nossas_imagens_parte_C/Jorge0.jpg" alt="letf01" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens_parte_C/Jorge1.jpg" alt="letf01" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens_parte_C/Jorge2.jpg" alt="letf01" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens_parte_C/Jorge3.jpg" alt="letf01" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens_parte_C/Jorge4.jpg" alt="letf01" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens_parte_C/Jorge5.jpg" alt="letf01" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens_parte_C/Jorge6.jpg" alt="letf01" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens_parte_C/Jorge7.jpg" alt="letf01" width="200" height=" 100">
</div>

<div style="display: flex; justify-content: center; gap: 1px;">
  <img src="/Lab2/Nossas_imagens_parte_C/Jorge8.jpg" alt="letf01" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens_parte_C/Jorge9.jpg" alt="letf01" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens_parte_C/Jorge10.jpg" alt="letf01" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens_parte_C/Jorge11.jpg" alt="letf01" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens_parte_C/Jorge12.jpg" alt="letf01" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens_parte_C/Jorge13.jpg" alt="letf01" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens_parte_C/Jorge14.jpg" alt="letf01" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens_parte_C/Jorge15.jpg" alt="letf01" width="200" height=" 100">
</div>

<div style="display: flex; justify-content: center">
  <figcaption>Figura X - Imagens geradas pelo grupo com câmera de maior distorção.</figcaption>
</div>

<h3 id="-d-grava-o-de-v-deo-da-c-mera">(D) Correção de distorção de imagens.</h3>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
 A parte D consiste em utilizar as fotos geradas pelos alunos (duas por aluno) para aplicar o comando de ajuste das distorções da imagem. As imagens originais e ajustadas são apresentadas na sessão <strong>Análise dos Resultados</strong>.
</p>

<h2 id="analise-dos-resultados">Análise dos Resultados</h2>

<h3 id="-a-leitura-de-imagem-em-arquivo">(A) Calibração de câmera com imagens fornecidas.</h3>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  As imagens a seguir são resultados do processamento feito pelo programa L2_cal.py. Em sequência são mostrados os resultados dos parâmetros calculados e as devidas considerações sobre cada um.
</p>

<div style="display: flex; justify-content: center; gap: 1px;">
  <img src="/Lab2/Resultados samples/resultado1.png" alt="letf01" width="400" height=" 200">
  <img src="/Lab2/Resultados samples/resultado2.png" alt="letf02" width="400" height=" 200">
  <img src="/Lab2/Resultados samples/resultado3.png" alt="letf03" width="400" height=" 200">
  <img src="/Lab2/Resultados samples/resultado4.png" alt="letf04" width="400" height=" 200">
  <img src="/Lab2/Resultados samples/resultado5.png" alt="letf05" width="400" height=" 200">
  <img src="/Lab2/Resultados samples/resultado6.png" alt="letf06" width="400" height=" 200">
  <img src="/Lab2/Resultados samples/resultado7.png" alt="letf07" width="400" height=" 200">
</div>

<div style="display: flex; justify-content: center; gap: 1px;">
  <img src="/Lab2/Resultados samples/resultado8.png" alt="letf08" width="400" height=" 200">
  <img src="/Lab2/Resultados samples/resultado9.png" alt="letf09" width="400" height=" 200">
  <img src="/Lab2/Resultados samples/resultado10.png" alt="letf11" width="400" height=" 200">
  <img src="/Lab2/Resultados samples/resultado11.png" alt="letf12" width="400" height=" 200">
  <img src="/Lab2/Resultados samples/resultado12.png" alt="letf13" width="400" height=" 200">
  <img src="/Lab2/Resultados samples/resultado13.png" alt="letf14" width="400" height=" 200">
</div>

<div style="display: flex; justify-content: center">
  <figcaption>Figura X - Processamento do programa nas imagens de amostra.</figcaption>
</div>


<pre><code>
    Camera matrix : 

[[536.07345295   0.         342.37047283]
 [  0.         536.01636331 235.53687701]
 [  0.           0.           1.        ]]
dist : 

[[-0.26509044 -0.04674186  0.00183301 -0.00031469  0.25231154]]
rvecs : 

(array([[-0.08398729],
       [ 0.34802798],
       [-1.54244125]]), array([[-0.27527313],
       [ 0.10123349],
       [-1.56296568]]), array([[-0.22584613],
       [ 1.0155115 ],
       [-2.79470623]]), array([[ 0.05280128],
       [-0.60171832],
       [-0.18453815]]), array([[-0.10141629],
       [ 0.32034812],
       [ 0.3147293 ]]), array([[-0.34698232],
       [-0.06738512],
       [-1.20088998]]), array([[0.06525918],
       [0.44701842],
       [0.10800013]]), array([[ 0.49542336],
       [ 0.11948808],
       [-0.29675958]]), array([[-0.37463355],
       [ 0.06982818],
       [-0.01937111]]), array([[-0.35339067],
       [ 0.24071863],
       [ 0.20970027]]), array([[-0.4735952 ],
       [ 0.08970834],
       [-0.22605981]]), array([[ 0.19721096],
       [-0.42009963],
       [-0.1949708 ]]), array([[ 0.48287277],
       [-0.17037078],
       [-1.40740327]]))
tvecs : 

(array([[-2.96218417],
       [ 0.57158932],
       [16.83013775]]), array([[-3.99388098],
       [ 2.27704343],
       [12.68878108]]), array([[ 2.53399419],
       [ 4.31999128],
       [13.71919122]]), array([[-2.16838794],
       [-3.50011196],
       [10.73694991]]), array([[-3.72585434],
       [-4.3108485 ],
       [17.20439703]]), array([[-3.427436  ],
       [ 0.4873819 ],
       [11.56153507]]), array([[ 2.20741839],
       [-3.21446613],
       [15.60125394]]), array([[-3.40557514],
       [-2.41042315],
       [12.58706804]]), array([[-2.95848731],
       [-3.94417974],
       [13.21423743]]), array([[-1.59004095],
       [-4.31771235],
       [14.01040668]]), array([[-2.51791826],
       [-3.43069105],
       [12.85702135]]), array([[-2.67642941],
       [-3.18945602],
       [10.58262241]]), array([[-3.50264637],
       [ 1.61595404],
       [11.97222152]]))

</p> 
</code></pre>

<h3>Significados de K, R, t, e dist.</h3>

<h4>A matriz <strong>K</strong></h4>
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
    A matriz <strong>K</strong> de parâmetros intrínsecos da câmera tem o seguinte padrão:
</p> 


<p style="text-align: center; line-height: 1.5;">
<code>
    [[fx    0.    cx]<br>
    [0.    fy    cy]<br>
    [0.    0.    1.]]
    
</code>
</p>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
    Onde fx e fy são as distâncias focais x e y, ou seja, representam o foco da câmera. Os parâmetros cx e cy representam o centro óptico do plano da imagem (geralmente o centro da imagem). O valor zero na primeira linha e segunda coluna da matriz representa a inclinação entre os eixos x e y, geralmente é atribuído o valor zero. Os zeros e o um na terceira linha são convenções da forma homogênea.
</p> 

<h4>A matriz <strong>R</strong> e o vetor <strong>t</strong></h4>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
    Para encontrar a projeção de um ponto 3D no plano da imagem, são necessários os parâmetros extrínsecos (Rotação <strong>R</strong> 3X1 e Translação <strong>t</strong> 3X1). A matriz de rotação <strong>R</strong> representa a rotação do ponto 3D do sistema de coordenadas do mundo (tabuleiro) para o sistema de coordenadas da câmera. O vetor <strong>t</strong> é o vetor translação do sistema de coordenadas do mundo para o sistema de coordenadas da câmera. A rotação no script é especificada como um vetor <strong>r</strong> de 3x1 para cada imagem usada na calibração. Esses vetores são em forma de rotação de Rodrigues, que é uma forma compacta de representar uma matriz de rotação 3x3.
</p> 


<h4>O vetor <strong>d</strong></h4>
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
    São os coeficientes de distorção da lente (termo dist):
</p> 

<p style="text-align: center; line-height: 1.5;">
<code>
    [[ k1 k2  p1  p2  k3]]    
</code>
</p>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
    Onde k1, k2 e k3 representam a distorção radial (faz as linhas retas parecerem curvas); 
    p1 e p2 a Distorção tangencial (causada por desalinhamento da lente com o sensor).
    Esses valores são usados para corrigir as distorções da imagem, muito comum em lentes baratas ou câmeras tipo webcam.
</p> 

<h3 id="-b-leitura-de-v-deo-em-arquivo">(B) Calibração da sua webcam com a captura de suas próprias imagens.</h3>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  As imagens a seguir são resultados do processamento feito pelo programa L2_cal.py aplicado às imagens geradas pelo grupo. Em sequência são mostrados os resultados dos parâmetros calculados.
</p>

<div style="display: flex; justify-content: center; gap: 1px;">
  <img src="/Lab2/Nossas_imagens_resultados_parteA/result1 (1).png" alt="letf01" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_resultados_parteA/result1 (2).png" alt="letf02" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_resultados_parteA/result1 (3).png" alt="letf03" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_resultados_parteA/result1 (4).png" alt="letf04" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_resultados_parteA/result1 (5).png" alt="letf05" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_resultados_parteA/result1 (6).png" alt="letf06" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_resultados_parteA/result1 (7).png" alt="letf07" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_resultados_parteA/result1 (8).png" alt="letf08" width="400" height="200">
</div>

<div style="display: flex; justify-content: center; gap: 1px;">

  <img src="/Lab2/Nossas_imagens_resultados_parteA/result1 (9).png" alt="letf09" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_resultados_parteA/result1 (10).png" alt="letf11" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_resultados_parteA/result1 (11).png" alt="letf12" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_resultados_parteA/result1 (12).png" alt="letf13" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_resultados_parteA/result1 (13).png" alt="letf14" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_resultados_parteA/result1 (14).png" alt="letf14" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_resultados_parteA/result1 (15).png" alt="letf08" width="400" height="200">
</div>

<div style="display: flex; justify-content: center">
  <figcaption>Figura X - Processamento das imagens geradas pelo grupo.</figcaption>
</div>



<pre><code>

 Camera matrix :

[[681.31313572   0.         338.83438339]
 [  0.         680.28102571 237.97905977]
 [  0.           0.           1.        ]]
dist : 

[[ 0.05471118 -0.23836225  0.00204913  0.00131733  0.62389174]]
rvecs : 

(array([[ 0.26322864],
       [-0.34981827],
       [-1.32321508]]), array([[ 0.2116112 ],
       [-0.67845162],
       [ 1.58437346]]), array([[-0.62979673],
       [ 0.16970115],
       [ 0.44629149]]), array([[-0.25428944],
       [-0.37829953],
       [ 1.3569295 ]]), array([[-0.60782013],
       [ 0.20990471],
       [ 1.44878658]]), array([[-0.03930657],
       [ 0.43935939],
       [ 0.07564065]]), array([[-0.01173043],
       [-0.20624347],
       [ 0.04343353]]), array([[ 0.14622958],
       [ 0.00891626],
       [-0.48988343]]), array([[-0.4256197 ],
       [ 0.53447939],
       [ 1.52917068]]), array([[ 0.04103005],
       [-0.61093764],
       [-0.12617062]]), array([[0.17272886],
       [0.13676318],
       [1.54935019]]), array([[-0.57484342],
       [-0.25358952],
       [-0.45894776]]), array([[-0.58606848],
       [-0.24621721],
       [-0.4505711 ]]), array([[-0.22169958],
       [-0.19357459],
       [ 1.45842311]]), array([[-0.10972886],
       [-0.21994229],
       [ 1.50904732]]))
tvecs : 

(array([[-4.33747823],
       [ 2.13449562],
       [12.45723853]]), array([[ 3.40912232],
       [-1.86336858],
       [11.35655984]]), array([[-1.46973137],
       [-4.36037833],
       [17.00324009]]), array([[ 2.71639352],
       [-3.45695725],
       [14.27153313]]), array([[ 2.60284186],
       [-2.54365767],
       [14.75721718]]), array([[-2.83528458],
       [-3.74506818],
       [17.21993768]]), array([[-1.38610851],
       [-3.44676457],
       [14.44166078]]), array([[-3.87938381],
       [-1.42681847],
       [16.6774393 ]]), array([[ 3.14630992],
       [-2.39024673],
       [13.62734449]]), array([[-2.76817882],
       [-3.32759211],
       [14.0338598 ]]), array([[ 2.89324534],
       [-2.60746396],
       [11.08565414]]), array([[-5.23329535],
       [-2.49602871],
       [15.74261591]]), array([[-5.0985607 ],
       [-2.510265  ],
       [15.62759254]]), array([[ 2.91085544],
       [-3.12904553],
       [12.5062273 ]]), array([[ 3.41157859],
       [-2.84304675],
       [12.53109819]]))
</p>
</code></pre>


<h4>Comparação com os resultados obtidos no item anterior</h4>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
Realiza-se a calibração de duas câmeras com o objetivo de extrair seus parâmetros intrínsecos e extrínsecos, além de avaliar as distorções ópticas associadas a cada dispositivo. A comparação considera a matriz intrínseca (K), o vetor de distorção (dist), os vetores de rotação (rvecs) e os vetores de translação (tvecs), obtidos por meio de um processo de calibração com imagens de padrão conhecido.
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
A matriz intrínseca da Câmera 1 apresenta distância focal estimada de aproximadamente 536 unidades em ambos os eixos (fx = 536.07, fy = 536.01). Já a Câmera 2 apresenta valores mais elevados (fx = 681.31, fy = 680.28), representando um aumento de cerca de 27%. Essa diferença indica que a Câmera 2 possui um campo de visão mais estreito e, portanto, uma capacidade de aproximação maior. Os valores do centro óptico (cx, cy) mantêm-se similares entre as duas câmeras, com pequenas variações (cerca de 1%), indicando boa centralização da imagem em ambos os sensores.
A comparação dos vetores de distorção revela características ópticas distintas. A Câmera 1 apresenta uma distorção radial negativa (k₁ = -0.265), característica do tipo barril, enquanto a Câmera 2 exibe uma distorção radial positiva mais branda (k₁ = +0.055), compatível com o tipo almofada. Além disso, o coeficiente de terceira ordem k₃ é significativamente maior na Câmera 2 (k₃ = +0.624), o que indica a presença de distorções de ordem superior mais acentuadas nesse dispositivo. Os coeficientes tangenciais (p₁, p₂) permanecem baixos em ambas as câmeras, sugerindo que a principal distorção ocorre na forma radial.
</p>
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
Os vetores de rotação (rvecs) demonstram que ambas as câmeras capturam o padrão de calibração sob diferentes orientações espaciais. A Câmera 1 exibe rotações com maior predominância no eixo z, enquanto a Câmera 2 distribui suas rotações de maneira mais equilibrada entre os três eixos, o que reflete abordagens distintas na aquisição das imagens utilizadas na calibração.
Em relação aos vetores de translação (tvecs), observa-se que ambas as câmeras operam com distâncias semelhantes em relação ao padrão de calibração, variando principalmente entre 10 e 17 unidades no eixo z. No entanto, a Câmera 2 apresenta maior variação nas componentes dos eixos x e y, o que sugere maior diversidade nos ângulos de captura e maior riqueza de pontos de vista.
Conclui-se que, apesar de ambas as câmeras fornecerem resultados consistentes dentro de seus respectivos contextos ópticos, os parâmetros calibrados refletem diferenças significativas em suas características físicas e ópticas. A Câmera 2 evidencia uma lente com maior aproximação (menor campo de visão), maior distorção radial de ordem elevada e variedade de poses de calibração. Já a Câmera 1 apresenta uma distorção mais típica do tipo barril e padrão de aquisição com rotação mais pronunciada sobre um único eixo. Essas diferenças destacam a importância de considerar as particularidades de cada dispositivo óptico na etapa de calibração para garantir precisão na reconstrução tridimensional ou na correção de imagens.
</p>

<h4>Apresente o valor númérico obtido pela calibração de sua câmera dos seguintes parâmetros: focal length, aspect ratio, skew, principal point, e comente esse resultado obtido.</h4>

<h4>Focal lenght</h4>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
<strong>Resultados:</strong> fx = 681,31313572 e fy = 680.28102571.
</p>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
A distância focal representa a relação entre as dimensões físicas da lente e o tamanho dos pixels no sensor, expressa aqui em pixels. Esses valores mostram que a câmera possui resolução uniforme nos eixos horizontal e vertical, com pequena diferença entre fx e fy, o que indica que os pixels são praticamente quadrados. Uma distância focal alta como essa também sugere um campo de visão mais estreito (zoom maior), típico de câmeras com lentes mais fechadas ou com padrão de calibração mais próximo.
</p>

<h4>Aspect ratio</h4>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
<strong>Resultados:</strong> aspect_ratio = fx / fy = 681.31313572 / 680.28102571 ≈ 1.0015.
</p>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
Esse valor está muito próximo de 1, o que indica que o tamanho dos pixels nos eixos x e y é praticamente o mesmo — ou seja, a imagem não sofre distorção por alongamento ou achatamento em nenhum dos eixos. Um aspect ratio diferente de 1 indicaria distorção geométrica intrínseca da imagem.
</p>

<h4>Skew</h4>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
<strong>Resultados:</strong> skew = 0.
</p>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;"></p>
Esse valor representa o grau de inclinação entre os eixos x e y do sensor. Um skew diferente de zero indicaria que os eixos não são ortogonais (formam um ângulo diferente de 90°), o que poderia ocorrer por imperfeições na montagem do sensor. O valor zero indica que os eixos da imagem estão corretamente perpendiculares, o que é esperado na maioria dos sensores modernos.  
</p>

<h4>Principal point (Centro óptico)</h4>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
<strong>Resultados:</strong> cx = 338,83438339, cy = 237,97905977.
</p>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
Esses valores representam a posição do centro da imagem em coordenadas de pixel. Idealmente, esse ponto coincidiria com o centro geométrico da imagem (largura/2, altura/2), mas na prática há um pequeno deslocamento, o que é comum. Esse deslocamento pode ser causado por leve descentralização da lente em relação ao sensor. A interpretação correta é que o centro óptico projetado no plano da imagem está deslocado de (cx, cy) em relação à origem do sistema de coordenadas da imagem (que geralmente é o canto superior esquerdo). Não se deve dizer que ele está “deslocado do centro óptico da câmera”, pois isso confundiria os conceitos físicos (lente) e projetivos (imagem).
</p>

<h4>Qual o motivo de resultar um conjunto R e t para cada imagem usada na calibração?</h4>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
Cada imagem utilizada na calibração apresenta o padrão de tabuleiro de xadrez em uma posição e orientação diferentes em relação à câmera. Por esse motivo, o algoritmo de calibração estima, para cada imagem individualmente, um conjunto distinto de vetores de rotação (R) e translação (t). Esses vetores descrevem a pose relativa do padrão no espaço tridimensional, ou seja, como o tabuleiro está posicionado e orientado no sistema de coordenadas da câmera. A matriz de rotação R define a orientação do plano do tabuleiro, enquanto o vetor de translação t representa a posição de seu centro em relação à câmera. Como cada imagem oferece uma visão única do padrão, é necessário calcular uma transformação específica para alinhar os pontos 3D do mundo (referência do tabuleiro) com os pontos 2D detectados na imagem. Assim, cada par R e t resulta da correspondência entre a geometria do mundo real e sua projeção na imagem capturada.
</p>

<h4>O que estas variáveis R e t significam perante os sistemas de coordenadas envolvidos?</h4>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
No contexto da calibração de câmeras, os parâmetros extrínsecos R (rotação) e t (translação) estabelecem a relação entre o sistema de coordenadas do mundo, definido pelo padrão de calibração (como um tabuleiro de xadrez), e o sistema de coordenadas da câmera. O objetivo é transformar um ponto 3D, originalmente definido no referencial do mundo, para o referencial da câmera, de modo que ele possa ser posteriormente projetado no plano da imagem.
</p>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
A matriz de rotação R (3×3) representa a orientação do sistema de coordenadas do mundo em relação ao da câmera. Essa matriz equivale à composição de três rotações em torno dos eixos (guinada, inclinação e rotação), mas é utilizada em forma matricial para permitir cálculos diretos por multiplicação linear. Já o vetor de translação t (3×1) indica o deslocamento do centro do padrão em relação ao centro da câmera, ou seja, a posição do objeto no espaço tridimensional sob o ponto de vista da câmera.
Durante o processo de captura de uma imagem, a câmera registra uma projeção bidimensional de pontos tridimensionais. Para realizar essa projeção corretamente, é necessário primeiro aplicar a transformação espacial (R|t), que converte os pontos do sistema do mundo para o sistema da câmera. Em seguida, a projeção desses pontos no plano da imagem é realizada por meio dos parâmetros intrínsecos da câmera. Portanto, as variáveis R e t são fundamentais para interpretar corretamente a posição e orientação dos objetos no espaço tridimensional em relação à câmera, permitindo a reconstrução da cena real a partir das imagens capturadas.
</p> 

<h3 id="-c-leitura-de-imagem-de-c-mera">(C) Calibração de outra câmera do laboratório</h3>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  As imagens a seguir são resultados do processamento feito pelo programa L2_cal.py aplicado às imagens geradas pelo grupo na câmera de maior distorção. Em sequência são mostrados os resultados dos parâmetros calculados.
</p>

<div style="display: flex; justify-content: center; gap: 1px;">
  <img src="/Lab2/Nossas_imagens_parte_C_resultados/resultados(2).png" alt="letf01" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_parte_C_resultados/resultados(3).png" alt="letf01" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_parte_C_resultados/resultados(4).png" alt="letf01" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_parte_C_resultados/resultados(5).png" alt="letf01" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_parte_C_resultados/resultados(6).png" alt="letf01" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_parte_C_resultados/resultados(7).png" alt="letf01" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_parte_C_resultados/resultados(8).png" alt="letf01" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_parte_C_resultados/resultados(9).png" alt="letf01" width="400" height="200">
</div>

<div style="display: flex; justify-content: center; gap: 1px;">
  <img src="/Lab2/Nossas_imagens_parte_C_resultados/resultados(10).png" alt="letf01" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_parte_C_resultados/resultados(11).png" alt="letf01" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_parte_C_resultados/resultados(12).png" alt="letf01" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_parte_C_resultados/resultados(13).png" alt="letf01" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_parte_C_resultados/resultados(14).png" alt="letf01" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_parte_C_resultados/resultados(15).png" alt="letf01" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_parte_C_resultados/resultados(16).png" alt="letf01" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_parte_C_resultados/resultados(17).png" alt="letf01" width="400" height="200">
</div>

<div style="display: flex; justify-content: center">
  <figcaption>Figura X - Processamento das imagens geradas pelo grupo com câmera de maior distorção..</figcaption>
</div>

<pre><code>
Camera matrix : 

[[588.061213     0.         322.57638831]
 [  0.         588.20498337 247.43327418]
 [  0.           0.           1.        ]]
dist : 

[[-3.94639155e-01  3.88505575e-01 -9.11347576e-04  2.88161247e-04
  -6.15711484e-01]]
rvecs : 

(array([[-0.42381565],
       [ 0.18602803],
       [ 1.36352981]]), array([[-0.13537295],
       [ 0.0103217 ],
       [ 0.69421391]]), array([[-0.2091288 ],
       [ 0.06540522],
       [ 1.03925791]]), array([[-0.20098521],
       [-0.01547093],
       [ 1.57343334]]), array([[-0.25398874],
       [-0.23916685],
       [-1.24808924]]), array([[-0.15324038],
       [-0.08513321],
       [-0.99705745]]), array([[ 0.0210668],
       [-0.1639967],
       [ 0.008342 ]]), array([[0.10258857],
       [0.37449714],
       [1.56303189]]), array([[-0.09171344],
       [-0.2147489 ],
       [-0.61110772]]), array([[-0.46346808],
       [-0.25024253],
       [ 1.48278525]]), array([[-0.38136412],
       [-0.36975439],
       [ 1.48623405]]), array([[0.53808104],
       [0.7464011 ],
       [1.47652293]]), array([[-0.43458938],
       [-0.63980879],
       [-1.47844253]]), array([[ 0.18889047],
       [-0.46269803],
       [-1.44698918]]), array([[ 0.33946917],
       [-0.66150471],
       [ 1.58206492]]), array([[ 0.33223252],
       [-0.59626991],
       [ 1.59085073]]))
tvecs : 

(array([[ 3.45080221],
       [-3.42803627],
       [12.0962708 ]]), array([[ 2.10091337],
       [-5.01656747],
       [15.03467777]]), array([[ 2.61012626],
       [-4.36812285],
       [14.06821609]]), array([[ 3.90266188],
       [-2.58413142],
       [11.6986545 ]]), array([[-2.71508814],
       [ 0.60294952],
       [10.72053887]]), array([[-2.85872128],
       [-0.71741432],
       [13.43184449]]), array([[-2.16876742],
       [-3.47183993],
       [11.41850321]]), array([[ 3.14111827],
       [-2.79792749],
       [ 9.42536904]]), array([[-1.85509934],
       [-1.72783005],
       [13.91120073]]), array([[ 3.63869764],
       [-2.84266505],
       [12.30349164]]), array([[ 2.72162072],
       [-3.02299477],
       [11.53568354]]), array([[ 2.66406183],
       [-2.42819361],
       [ 9.66006176]]), array([[-2.41316349],
       [ 1.14174974],
       [ 9.84747585]]), array([[-1.11709926],
       [ 1.95642534],
       [ 9.16507106]]), array([[ 3.70250962],
       [-1.58357202],
       [ 8.78719727]]), array([[ 4.72244519],
       [-1.86198736],
       [11.75868821]]))
</p>
</code></pre>
<section id="parte-c">

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  As imagens capturadas pela câmera C foram processadas pelo programa <code>L2_cal.py</code>, gerando a seguinte matriz intrínseca:
</p>
  <pre>
K_C = [[588.0841,   0.0000, 322.3735],
       [ 0.0000, 588.3452, 247.2104],
       [ 0.0000,   0.0000,   1.0000]]
  </pre>

 <p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  Os coeficientes de distorção radial e tangencial encontrados foram:
</p>

  <pre>
dist_C = [k₁ = –0.3954, k₂ = +0.3892, k₃ = –0.6167, p₁ = +0.0041, p₂ = –0.0011]
  </pre>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  Em comparação à Parte A (onde fx ≈ 536 e k₁ ≈ –0.265) e à Parte B (fx ≈ 681 e k₁ ≈ +0.055), nota‑se que a câmera C apresenta um foco intermediário (fx ≈ 588), resultando num campo de visão mais fechado que A, porém mais amplo que B. O centro óptico deslocou‑se de (342, 236) em A e de (338, 237) em B para (322, 247) em C, indicando um alinhamento mais centralizado nesta câmera.
</p>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  Quanto aos coeficientes de distorção, k₁ = –0.395 evidencia uma forte distorção de barril, superior àquela observada em A e oposta à suavização de almofada em B. Os sinais alternados de k₂ e k₃ confirmam uma curvatura radial mais complexa nas bordas da imagem, enquanto os valores muito próximos de zero para p₁ e p₂ demonstram que não há distorção tangencial relevante.
</p>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  Os vetores de rotação (rvecs) e translação (tvecs) para cada uma das 12 imagens mostram uma distribuição de poses mais heterogênea do que em A e B, refletindo ângulos e distâncias de captura variados. Isso reforça a importância de utilizar múltiplas visadas do padrão para obter uma calibração robusta.
</p>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  O aspect ratio calculado (fx/fy ≈ 588.08/588.35 ≈ 0.9995) permanece muito próximo de 1, e o skew é exatamente 0, indicando que os pixels são praticamente quadrados e os eixos x e y permanecem ortogonais. Esse comportamento ideal facilita a aplicação direta da matriz de calibração em projetos de visão computacional sem necessidade de correções adicionais.
</p>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  Em suma, a calibração da câmera C confirma a necessidade de tratar cada dispositivo isoladamente. Apesar de apresentar boa simetria interna, a lente desta câmera impõe uma distorção radial de ordem superior significativamente mais intensa do que as anteriores. Para aplicações como reconstrução 3D ou realidade aumentada, é fundamental aplicar a retificação adequada a fim de garantir a precisão geométrica desejada.
</p>


</section>


<h3 id="-d-grava-o-de-v-deo-da-c-mera">(D) Correção de distorção de imagens.</h3>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  Para correções de distorções nas imagens utilizamos o seguinte script:
</p>

<pre>
<code class="language-python">
import cv2
import numpy as np
import glob

# === PARÂMETROS DA CÂMERA COM DISTORÇÃO ===
K = np.array([[588.061213, 0., 322.57638831],
              [0., 588.20498337, 247.43327418],
              [0., 0., 1.]])

dist = np.array([[-0.39463915, 0.38850557, -0.00091135, 0.00028816, -0.61571148]])

# === OPÇÃO: caminho para as imagens capturadas com essa câmera ===
image_files = glob.glob("distorcida/*.jpg")  # coloque suas imagens na pasta "distorcida/"

# === CRIA A PASTA DE SAÍDA SE NÃO EXISTIR ===
import os
os.makedirs("corrigida", exist_ok=True)

for fname in image_files:
    img = cv2.imread(fname)
    h, w = img.shape[:2]

    # Cálculo da nova matriz da câmera (corrigida)
    new_K, roi = cv2.getOptimalNewCameraMatrix(K, dist, (w,h), alpha=1, centerPrincipalPoint=True)

    # Corrige a distorção
    undistorted = cv2.undistort(img, K, dist, None, new_K)

    # (Opcional) Recorte para remover áreas pretas
    x, y, w, h = roi
    undistorted = undistorted[y:y+h, x:x+w]

    # Salvar imagem corrigida
    name = os.path.basename(fname)
    cv2.imwrite(f"corrigida/corrigida_{name}", undistorted)
    print(f"Corrigida: {name}")

print("\n✅ Todas as imagens foram corrigidas e salvas na pasta 'corrigida/'")
</code>
</pre>


<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  As imagens a seguir mostram os resultados das correções das distorções. Do lado esquerdo as imagens originais e do lado direito as imagens corrigidas.
</p>

<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab2/ParteD/Jorge16.jpg" alt="letf01" width="600" height="300"> 
  <img src="/Lab2/ParteD/corrigida/corrigida_Jorge16.jpg" alt="letf01" width="600" height="300">
</div>

<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab2/ParteD/Jorge17.jpg" alt="letf01" width="600" height="300">
  <img src="/Lab2/ParteD/corrigida/corrigida_Jorge17.jpg" alt="letf01" width="600" height="300">
</div>

<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab2/ParteD/Jorge18.jpg" alt="letf01" width="600" height="300">
  <img src="/Lab2/ParteD/corrigida/corrigida_Jorge18.jpg" alt="letf01" width="600" height="300">
</div>

<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab2/ParteD/Jorge19.jpg" alt="letf01" width="600" height="300">
  <img src="/Lab2/ParteD/corrigida/corrigida_Jorge19.jpg" alt="letf01" width="600" height="300">
</div>

<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab2/ParteD/Jorge20.jpg" alt="letf01" width="600" height="300">
  <img src="/Lab2/ParteD/corrigida/corrigida_Jorge20.jpg" alt="letf01" width="600" height="300">
</div>

<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab2/ParteD/Jorge21.jpg" alt="letf01" width="600" height="300">
  <img src="/Lab2/ParteD/corrigida/corrigida_Jorge21.jpg" alt="letf01" width="600" height="300">
</div>

<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab2/ParteD/Jorge22.jpg" alt="letf01" width="600" height="300">
  <img src="/Lab2/ParteD/corrigida/corrigida_Jorge22.jpg" alt="letf01" width="600" height="300">
</div>

<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab2/ParteD/Jorge23.jpg" alt="letf01" width="600" height="300">
  <img src="/Lab2/ParteD/corrigida/corrigida_Jorge23.jpg" alt="letf01" width="600" height="300">
</div>

<div style="display: flex; justify-content: center">
  <figcaption>Figura X - Resultados parte D.</figcaption>
</div>

<section>
  <h2>Processo de Calibração da Câmera</h2>

  <p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
    A calibração de câmera é uma etapa fundamental em aplicações de Visão Computacional, como reconstrução 3D,
    realidade aumentada e medição de distâncias. Seu principal objetivo é encontrar os parâmetros que descrevem
    matematicamente como a câmera transforma pontos do mundo real (3D) em pontos na imagem (2D).
  </p>

  <h3>1. Captura das Imagens com Tabuleiro de Xadrez</h3>
  <p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
    Foram capturadas diversas imagens de um padrão conhecido — um tabuleiro de xadrez — posicionadas sob diferentes
    ângulos e distâncias em relação à câmera. Esse padrão foi escolhido por apresentar cantos bem definidos e regularmente espaçados, ideais para detecção automática.
  </p>

  <h3>2. Detecção de Cantos</h3>
 <p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
    Em cada imagem, foi utilizado o algoritmo <code>cv2.findChessboardCorners()</code> para localizar automaticamente
    os cantos internos do tabuleiro. Em seguida, a função <code>cv2.cornerSubPix()</code> foi aplicada para refinar a posição desses
    cantos com precisão subpixel.
  </p>

  <h3>3. Associação de Pontos 3D ↔ 2D</h3>
  <p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
    Para cada imagem foram associados:
    <ul>
      <li><strong>Pontos 3D:</strong> Coordenadas reais dos cantos no plano do tabuleiro (com Z = 0), definidas em um sistema de coordenadas arbitrário.</li>
      <li><strong>Pontos 2D:</strong> Coordenadas dos pixels onde os cantos foram detectados na imagem.</li>
    </ul>
    Essa correspondência foi utilizada como base para estimar os parâmetros da câmera.
  </p>

  <h3>4. Cálculo dos Parâmetros com <code>cv2.calibrateCamera()</code></h3>
  <p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
    A função <code>cv2.calibrateCamera()</code> foi utilizada para estimar os seguintes parâmetros:
  </p>

  <ul>
    <li>
      <strong>Matriz Intrínseca (K):</strong> Representa as propriedades internas da câmera, como:
      <ul>
        <li>Distâncias focais em pixels (<code>fx</code>, <code>fy</code>)</li>
        <li>Coordenadas do centro óptico da imagem (<code>cx</code>, <code>cy</code>)</li>
      </ul>
      <pre>
K = | fx  0  cx |
    | 0  fy  cy |
    | 0   0   1 |
      </pre>
    </li>

    <li>
      <strong>Coeficientes de Distorção:</strong> Utilizados para modelar e corrigir imperfeições ópticas da lente, incluindo distorção radial e tangencial.
      <pre>
dist = [k1, k2, p1, p2, k3]
      </pre>
    </li>

    <li>
      <strong>Vetores de Rotação (rvecs):</strong> Representam a orientação da câmera em relação ao tabuleiro em cada imagem capturada.
    </li>
    <li>
      <strong>Vetores de Translação (tvecs):</strong> Representam a posição da câmera em relação ao plano do tabuleiro.
    </li>
  </ul>

  <h3>5. Correção da Distorção (Undistortion)</h3>
  <p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
    Após a calibração, foi possível corrigir as distorções nas imagens aplicando a função <code>cv2.undistort()</code>.
    Essa etapa remove os efeitos ópticos indesejados e aproxima a imagem da sua geometria real.
  </p>

  <h3>6. Aplicações Práticas</h3>
  <p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
    A calibração permite:
    <ul>
      <li>Corrigir distorções em imagens capturadas</li>
      <li>Realizar medições precisas de distância e ângulos</li>
      <li>Projetar corretamente objetos virtuais em imagens reais (realidade aumentada)</li>
      <li>Estimar a pose da câmera no espaço tridimensional</li>
    </ul>
  </p>

<section>
  <h2>Correção de Distorção com Remapeamento</h2>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
    Para correções de distorções nas imagens utilizando o remaeamento, tem-se o seguinte código em Python:

  <pre><code class="language-python">
import cv2 as cv
import numpy as np

# Parâmetros calibrados da câmera
mtx = ... # Matriz intrínseca
dist = ... # Coeficientes de distorção

img = cv.imread("imagem_distorcida.jpg")
h, w = img.shape[:2]

# Calcula nova matriz de câmera e ROI
nova_mtx, roi = cv.getOptimalNewCameraMatrix(mtx, dist, (w, h), 1, (w, h))

# Gera os mapas de remapeamento
mapx, mapy = cv.initUndistortRectifyMap(mtx, dist, None, nova_mtx, (w, h), cv.CV_32FC1)

# Aplica remapeamento para corrigir a imagem
imagem_corrigida = cv.remap(img, mapx, mapy, cv.INTER_LINEAR)

# Recorte da imagem final (opcional)
x, y, w, h = roi
imagem_corrigida = imagem_corrigida[y:y+h, x:x+w]

cv.imwrite("imagem_corrigida.png", imagem_corrigida)
  </code></pre>
<section>

  <p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  As imagens a seguir mostram os resultados das correções das distorções utilizando remapping. Do lado esquerdo as imagens originais e do lado direito as imagens corrigidas.
</p>

<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab2/ParteD/Jorge16.jpg" alt="letf01" width="600" height="300"> 
  <img src="/Lab2/corrigida_remap/corrigida_Jorge16.jpg" alt="letf01" width="600" height="300">
</div>

<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab2/ParteD/Jorge17.jpg" alt="letf01" width="600" height="300">
<img src="/Lab2/corrigida_remap/corrigida_Jorge17.jpg" alt="letf01" width="600" height="300">
</div>

<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab2/ParteD/Jorge18.jpg" alt="letf01" width="600" height="300">
  <img src="/Lab2/corrigida_remap/corrigida_Jorge18.jpg" alt="letf01" width="600" height="300">
</div>

<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab2/ParteD/Jorge19.jpg" alt="letf01" width="600" height="300">
  <img src="/Lab2/corrigida_remap/corrigida_Jorge19.jpg" alt="letf01" width="600" height="300">
</div>

<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab2/ParteD/Jorge20.jpg" alt="letf01" width="600" height="300">
  <img src="/Lab2/corrigida_remap/corrigida_Jorge20.jpg" alt="letf01" width="600" height="300">
</div>

<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab2/ParteD/Jorge21.jpg" alt="letf01" width="600" height="300">
  <img src="/Lab2/corrigida_remap/corrigida_Jorge21.jpg" alt="letf01" width="600" height="300">
</div>

<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab2/ParteD/Jorge22.jpg" alt="letf01" width="600" height="300">
  <img src="/Lab2/corrigida_remap/corrigida_Jorge22.jpg" alt="letf01" width="600" height="300">
</div>

<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab2/ParteD/Jorge23.jpg" alt="letf01" width="600" height="300">
  <img src="/Lab2/corrigida_remap/corrigida_Jorge23.jpg" alt="letf01" width="600" height="300">
</div>
<div style="display: flex; justify-content: center">
  <figcaption>Figura X - Resultados parte D. utilizando remapeamento</figcaption>
</div>
    
  <h2>Correção de Distorção com Remapeamento</h2>

  <p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
    Uma alternativa mais flexível e eficiente à função <code>cv2.undistort()</code> é a utilização do processo de 
    remapeamento, que consiste na separação entre a geração do mapeamento geométrico e a aplicação da transformação 
    nos pixels da imagem. Esse método é particularmente indicado para aplicações com múltiplos quadros ou processamento 
    em tempo real.
  </p>

  <h3>1. Geração dos Mapas de Remapeamento</h3>
  <p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
    A função <code>cv2.initUndistortRectifyMap()</code> é utilizada para calcular dois mapas:
    <ul>
      <li><strong>mapx:</strong> contém as coordenadas horizontais de onde cada pixel corrigido deve buscar seu valor na imagem original.</li>
      <li><strong>mapy:</strong> contém as coordenadas verticais correspondentes.</li>
    </ul>
    Esses mapas são calculados com base na matriz intrínseca da câmera, nos coeficientes de distorção e em uma matriz de câmera ajustada.
  </p>

  <h3>2. Aplicação do Remapeamento</h3>
  <p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
    Após a criação dos mapas, a função <code>cv2.remap()</code> é responsável por aplicar a transformação à imagem original,
    utilizando interpolação bilinear para gerar uma imagem corrigida geometricamente.
  </p>

  <h3>3. Recorte da Imagem Corrigida</h3>
  <p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
    Como resultado da correção, podem surgir regiões pretas nas bordas da imagem. A função 
    <code>cv2.getOptimalNewCameraMatrix()</code> fornece uma <code>ROI</code> (Região de Interesse), que pode ser utilizada 
    para recortar apenas a área útil da imagem corrigida.
  </p>


  <h3>Vantagens do Método de Remapeamento</h3>
  <ul>
    <li>Maior eficiência computacional em aplicações com vídeo ou múltiplas imagens.</li>
    <li>Separação clara entre cálculo geométrico e transformação da imagem.</li>
    <li>Mapas de remapeamento podem ser reutilizados, economizando tempo de processamento.</li>
    <li>Permite controle mais preciso sobre interpolação e ajuste do campo de visão.</li>
  </ul>

  <p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
    Dessa forma, o uso de remapeamento é especialmente indicado em sistemas de visão computacional embarcados,
    processamento em tempo real, robótica e realidade aumentada, onde eficiência e precisão são fatores cruciais.
  </p>
</section>

  <p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  As imagens a seguir servem para comparar os ajustes utilizando remmaping à esquerda e undistort à disreita.
</p>
  <div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab2/corrigida_remap/corrigida_Jorge23.jpg" alt="letf01" width="600" height="300">
  <img src="/Lab2/ParteD/corrigida/corrigida_Jorge23.jpg" alt="letf01" width="600" height="300">
</div>
  <div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab2/corrigida_remap/corrigida_Jorge21.jpg" alt="letf01" width="600" height="300">
  <img src="/Lab2/ParteD/corrigida/corrigida_Jorge21.jpg" alt="letf01" width="600" height="300">
</div>
    <div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab2/corrigida_remap/corrigida_Jorge22.jpg" alt="letf01" width="600" height="300">
  <img src="/Lab2/ParteD/corrigida/corrigida_Jorge22.jpg" alt="letf01" width="600" height="300">
</div>
<div style="display: flex; justify-content: center">
  <figcaption>Figura X+1 - Comparação entre os ajustes</figcaption>
</div>
  
  <p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  Vale notar nas regiões centreais é perceptível uma leve melhora na qualidade das imagens, isso se deve porque o remapeamento permite uma interpolação mais controlada, preservando a qualidade das imagens originais e ajustando a distorção.
</p>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
    Por essas razões, o uso de remapeamento é preferido em sistemas que exigem alto desempenho ou precisão contínua,
    como sistemas de visão computacional embarcados ou aplicações de realidade aumentada.
  </p>
</section>

  <p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
    E possível notar grandes melhorias com relação às distorções, em ambas as correções nota-se que as janelas tortas foram alinhadas, canos nos tetos e barras de metal que antes faziam curvas na câmera com distorção se tornaram retos com a correção das imagens. Quanto mais radial está o objeto na imagem original, mais torto (distorcido) ele estava, porém ao corrigir a distorção, tanto com undistort quanto remapping os objetos se tornam retos novamente mesmo estando na parte radial (próximo à margem) da imagem. 
  </p>


<h2 id="conclus-o">Conclusão</h2>
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
A respeito da parte A e da parte B e suas comparações conclui-se que os parâmetros obtidos indicam uma calibração consistente e compatível com sensores de qualidade. O valor do aspect ratio próximo de 1 confirma que os pixels do sensor possuem proporções praticamente quadradas, o que garante uniformidade na escala dos eixos e favorece aplicações que assumem simetria na resolução. O valor nulo do skew revela que os eixos da imagem são ortogonais, o que é desejável e caracteriza uma montagem precisa do sensor da câmera. Além disso, o pequeno deslocamento do principal point em relação ao centro da imagem é esperado na prática e não compromete os resultados da calibração. A proximidade entre os valores de fx e fy também sugere uma boa uniformidade entre os eixos horizontal e vertical, o que simplifica o uso desses parâmetros em aplicações como reconstrução tridimensional, visão estéreo e correção de distorção.
</p>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
A respeito da parte C, conclui-se que a calibração da segunda câmera utilizada no laboratório, revela características ópticas e geométricas específicas que a diferenciam da primeira câmera analisada, exigindo atenção individualizada em sua aplicação. A análise da matriz intrínseca, dos coeficientes de distorção e dos vetores de pose demonstra não apenas a consistência interna dos parâmetros estimados, mas também a complexidade das distorções radiais presentes, que podem comprometer a acurácia de sistemas computacionais sensíveis à geometria da imagem. Assim, reforça-se a importância da calibração criteriosa e da posterior correção dessas distorções em cenários que demandam alta fidelidade espacial, como visão computacional, modelagem tridimensional e aplicações de realidade aumentada.
</p>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
 A respeito da parte D, com base na análise apresentada, conclui-se que o método de remapeamento representa uma abordagem mais robusta e eficiente para a correção de distorções ópticas em imagens de câmeras calibradas, especialmente em contextos de processamento contínuo ou em tempo real. Ao permitir a separação entre o cálculo geométrico e a aplicação da transformação, o remapeamento proporciona maior flexibilidade, reutilização de mapas e controle refinado sobre interpolações. Os resultados experimentais reforçam sua superioridade frente ao método tradicional cv2.undistort(), evidenciando melhorias visuais perceptíveis, sobretudo nas regiões periféricas das imagens, onde as distorções radiais são mais acentuadas. Dessa forma, o remapeamento consolida-se como a técnica preferencial em aplicações de visão computacional embarcada, robótica e realidade aumentada, contribuindo significativamente para a fidelidade geométrica e a qualidade visual das imagens corrigidas. 
</p>

<h3>Referências</h3>
  <p>
    LEARNOPENCV. Geometry of Image Formation. Disponível em: https://learnopencv.com/geometry-of-image-formation/. Acesso em: 2 jul. 2025.
  </p>
  <p>
    LEARNOPENCV. Camera Calibration using OpenCV. Disponível em: https://learnopencv.com/camera-calibration-using-opencv/. Acesso em: 2 jul. 2025.
  </p>
  <p>
    OPENCV. Camera calibration with OpenCV. Disponível em: https://docs.opencv.org/4.x/dc/dbb/tutorial_py_calibration.html. Acesso em: 2 jul. 2025.
  </p>
</section>
  
