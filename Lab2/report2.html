<head>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>
</head>

<h1 id="relat-rio-laborat-rio-1">Relatório Laboratório 2 - Calibração de Câmeras</h1>
<p>Jorge Luiz Pinto Junior  - RA: 11058715 - CEO</p>
<p>Marcos Baldrigue Andrade - RA: 11201921777 - CFO - Financeiro</p>
<p>Guilherme Eduardo Pereira - RA: 11201720498 - CPO - Desenvolvimento</p>
<p>Data de realização do experimento: 25/06/2025</p>
<p>Data de publicação do relatório: 02/07/2025</p>
<h2 id="introdu-o">Introdução</h2>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
Este laboratório experimental tem como objetivo proporcionar aos alunos a compreensão dos conceitos fundamentais relacionados aos parâmetros intrínsecos e extrínsecos de câmeras, por meio da realização de um experimento prático de calibração. A atividade é dividida em quatro etapas sequenciais. Na primeira (Etapa A), realiza-se a calibração de uma câmera utilizando imagens fornecidas previamente, com o auxílio do programa L2_cal.py. Em seguida (Etapa B), os alunos geram suas próprias imagens com auxílio do programa L2_chess.py, capturando um padrão de tabuleiro de xadrez em diferentes orientações, e as utilizam para uma nova calibração com o L2_cal.py. Na terceira fase (Etapa C), o mesmo procedimento é repetido com uma segunda câmera, que apresenta maior distorção óptica. Por fim (Etapa D), os alunos produzem imagens adicionais com essa segunda câmera, com o objetivo de aplicar a correção de distorções previamente identificadas. 
</p> 

<h2 id="procedimentos-experimentais">Procedimentos Experimentais</h2>

<h3 id="-a-leitura-de-imagem-em-arquivo">(A) Calibração de câmera com imagens fornecidas.</h3>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
O programa abaixo (L2_cal.py) executa o processo de calibração de câmeras e tem por resultado os seguintes parâmetros: a matriz <strong>K</strong>, o vetor <strong>R</strong> , o vetor <strong>d</strong> e o vetor <strong>t</strong>. Estes parâmetros são explicados em detalhes na sessão de <strong>Análise dos Resultados</strong>. A execução correta do programa exige que o mesmo esteja dentro da pasta contendo as imagens que serão utilizadas para a calibração, nesta mesma pasta foi aberto o terminal do linux para execução do programa.
</p> 

<pre>
<code class="language-python">
import cv2
import numpy as np
import os
import glob

# Defining the dimensions of checkerboard
CHECKERBOARD = (6,9)
criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)

# Creating vector to store vectors of 3D points for each checkerboard image
objpoints = []
# Creating vector to store vectors of 2D points for each checkerboard image
imgpoints = [] 

# Defining the world coordinates for 3D points
objp = np.zeros((1, CHECKERBOARD[0] * CHECKERBOARD[1], 3), np.float32)
objp[0,:,:2] = np.mgrid[0:CHECKERBOARD[0], 0:CHECKERBOARD[1]].T.reshape(-1, 2)

# Extracting path of individual image stored in a given directory
images = glob.glob('*.jpg')
for fname in images:
    img = cv2.imread(fname)
    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
    ret, corners = cv2.findChessboardCorners(
        gray, CHECKERBOARD, 
        cv2.CALIB_CB_ADAPTIVE_THRESH + 
        cv2.CALIB_CB_FAST_CHECK + 
        cv2.CALIB_CB_NORMALIZE_IMAGE)
    
    if ret == True:
        objpoints.append(objp)
        corners2 = cv2.cornerSubPix(gray, corners, (11,11), (-1,-1), criteria)
        imgpoints.append(corners2)
        img = cv2.drawChessboardCorners(img, CHECKERBOARD, corners2, ret)
    
    cv2.imshow('img', img)
    cv2.waitKey(0)

cv2.destroyAllWindows()

h, w = img.shape[:2]

ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(
    objpoints, imgpoints, gray.shape[::-1], None, None)

print("Camera matrix : \n", mtx)
print("dist : \n", dist)
print("rvecs : \n", rvecs)
print("tvecs : \n", tvecs)
</code>
</pre>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  A seguir são mostradas as imagens utilizadas para calibrar a câmera. As imagens processadas pelo programa são mostradas na sessão <strong>Análise dos Resultados</strong>.
</p>

<div style="display: flex; justify-content: center; gap: 1px;">
  <img src="/Lab2/samples/left01.jpg" alt="letf01" width="200" height=" 100">
  <img src="/Lab2/samples/left02.jpg" alt="letf02" width="200" height=" 100">
  <img src="/Lab2/samples/left03.jpg" alt="letf03" width="200" height=" 100">
  <img src="/Lab2/samples/left04.jpg" alt="letf04" width="200" height=" 100">
  <img src="/Lab2/samples/left05.jpg" alt="letf05" width="200" height=" 100">
  <img src="/Lab2/samples/left06.jpg" alt="letf06" width="200" height=" 100">
  <img src="/Lab2/samples/left07.jpg" alt="letf07" width="200" height=" 100">
</div>

<div style="display: flex; justify-content: center; gap: 1px;">
  <img src="/Lab2/samples/left08.jpg" alt="letf08" width="200" height=" 100">
  <img src="/Lab2/samples/left09.jpg" alt="letf09" width="200" height=" 100">
  <img src="/Lab2/samples/left11.jpg" alt="letf11" width="200" height=" 100">
  <img src="/Lab2/samples/left12.jpg" alt="letf12" width="200" height=" 100">
  <img src="/Lab2/samples/left13.jpg" alt="letf13" width="200" height=" 100">
  <img src="/Lab2/samples/left14.jpg" alt="letf14" width="200" height=" 100">
</div>

<div style="display: flex; justify-content: center">
  <figcaption>Figura 1 - Samples.</figcaption>
</div>


<h3 id="-b-leitura-de-v-deo-em-arquivo">(B) Calibração da sua webcam com a captura de suas próprias imagens.</h3>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  As imagens a seguir foram geradas pelo grupo e utilizadas pelo programa L2_cal.py para calibrar a câmera novamente (mesma câmera da parte A). Um ajuste no programa se fez necessário, pois, o tabuleiro utilizado nas imagens de amostra tem tamanho de 6x9, enquanto que o tabuleiro utilizado no laboratório tem tamanho 6x8, a seguir a trecho modificado do programa (dimensões do tabuleiro):
</p>

<div style="display: flex; justify-content: center; gap: 1px;">
  <img src="/Lab2/Nossas_imagens/Ajuste_Programa.jpg" alt="letf01" width="600" height=" 200">
</div>

  <div style="display: flex; justify-content: center">
    <figcaption>Figura X - Ajuste no programa L2_cal.py.</figcaption>
  </div>

<div style="display: flex; justify-content: center; gap: 1px;">
  <img src="/Lab2/Nossas_imagens/Jorge0.jpg" alt="letf01" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens/Jorge1.jpg" alt="letf02" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens/Jorge2.jpg" alt="letf03" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens/Jorge3.jpg" alt="letf04" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens/Jorge4.jpg" alt="letf05" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens/Jorge5.jpg" alt="letf06" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens/Jorge6.jpg" alt="letf07" width="200" height=" 100">
</div>

<div style="display: flex; justify-content: center; gap: 1px;">
  <img src="/Lab2/Nossas_imagens/Jorge7.jpg" alt="letf08" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens/Jorge8.jpg" alt="letf09" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens/Jorge9.jpg" alt="letf11" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens/Jorge11.jpg" alt="letf12" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens/Jorge13.jpg" alt="letf13" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens/Jorge14.jpg" alt="letf14" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens/Jorge15.jpg" alt="letf14" width="200" height=" 100">
</div>

<div style="display: flex; justify-content: center">
  <figcaption>Figura X - Imagens geradas pelo grupo.</figcaption>
</div>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  O resultado do processamento das imagens se encontra na sessão <strong>Análise dos Resultados</strong>.
</p>

<h3 id="-c-leitura-de-imagem-de-c-mera">(C) Calibração de outra câmera do laboratório</h3>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
 Para realização da parte C, foi utilizada outra câmera fornecida no laboratório, esta possui distorção de imagem superior do que a câmera utilizada nas partes A e B. As imagens utilizadas para calibração são as mesmas da parte B. Os resultados são apresentados na sessão <strong>Análise dos Resultados</strong>. A seguir são apresentadas as imagens geradas através do programa L2_chess.py:
</p>

<div style="display: flex; justify-content: center; gap: 1px;">
  <img src="/Lab2/Nossas_imagens_parte_C/Jorge0.jpg" alt="letf01" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens_parte_C/Jorge1.jpg" alt="letf01" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens_parte_C/Jorge2.jpg" alt="letf01" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens_parte_C/Jorge3.jpg" alt="letf01" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens_parte_C/Jorge4.jpg" alt="letf01" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens_parte_C/Jorge5.jpg" alt="letf01" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens_parte_C/Jorge6.jpg" alt="letf01" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens_parte_C/Jorge7.jpg" alt="letf01" width="200" height=" 100">
</div>

<div style="display: flex; justify-content: center; gap: 1px;">
  <img src="/Lab2/Nossas_imagens_parte_C/Jorge8.jpg" alt="letf01" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens_parte_C/Jorge9.jpg" alt="letf01" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens_parte_C/Jorge10.jpg" alt="letf01" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens_parte_C/Jorge11.jpg" alt="letf01" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens_parte_C/Jorge12.jpg" alt="letf01" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens_parte_C/Jorge13.jpg" alt="letf01" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens_parte_C/Jorge14.jpg" alt="letf01" width="200" height=" 100">
  <img src="/Lab2/Nossas_imagens_parte_C/Jorge15.jpg" alt="letf01" width="200" height=" 100">
</div>

<div style="display: flex; justify-content: center">
  <figcaption>Figura X - Imagens geradas pelo grupo com câmera de maior distorção.</figcaption>
</div>

<h3 id="-d-grava-o-de-v-deo-da-c-mera">(D) Correção de distorção de imagens.</h3>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
 A parte D consiste em utilizar as fotos geradas pelos alunos (duas por aluno) para aplicar o comando de ajuste das distorções da imagem. As imagens originais e ajustadas são apresentadas na sessão <strong>Análise dos Resultados</strong>.
</p>

<h2 id="analise-dos-resultados">Análise dos Resultados</h2>

<h3 id="-a-leitura-de-imagem-em-arquivo">(A) Calibração de câmera com imagens fornecidas.</h3>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  As imagens a seguir são resultados do processamento feito pelo programa L2_cal.py. Em sequência são mostrados os resultados dos parâmetros calculados e as devidas considerações sobre cada um.
</p>

<div style="display: flex; justify-content: center; gap: 1px;">
  <img src="/Lab2/Resultados samples/resultado1.png" alt="letf01" width="400" height=" 200">
  <img src="/Lab2/Resultados samples/resultado2.png" alt="letf02" width="400" height=" 200">
  <img src="/Lab2/Resultados samples/resultado3.png" alt="letf03" width="400" height=" 200">
  <img src="/Lab2/Resultados samples/resultado4.png" alt="letf04" width="400" height=" 200">
  <img src="/Lab2/Resultados samples/resultado5.png" alt="letf05" width="400" height=" 200">
  <img src="/Lab2/Resultados samples/resultado6.png" alt="letf06" width="400" height=" 200">
  <img src="/Lab2/Resultados samples/resultado7.png" alt="letf07" width="400" height=" 200">
</div>

<div style="display: flex; justify-content: center; gap: 1px;">
  <img src="/Lab2/Resultados samples/resultado8.png" alt="letf08" width="400" height=" 200">
  <img src="/Lab2/Resultados samples/resultado9.png" alt="letf09" width="400" height=" 200">
  <img src="/Lab2/Resultados samples/resultado10.png" alt="letf11" width="400" height=" 200">
  <img src="/Lab2/Resultados samples/resultado11.png" alt="letf12" width="400" height=" 200">
  <img src="/Lab2/Resultados samples/resultado12.png" alt="letf13" width="400" height=" 200">
  <img src="/Lab2/Resultados samples/resultado13.png" alt="letf14" width="400" height=" 200">
</div>

<div style="display: flex; justify-content: center">
  <figcaption>Figura X - Processamento do programa nas imagens de amostra.</figcaption>
</div>


<pre><code>
    Camera matrix : 

[[536.07345295   0.         342.37047283]
 [  0.         536.01636331 235.53687701]
 [  0.           0.           1.        ]]
dist : 

[[-0.26509044 -0.04674186  0.00183301 -0.00031469  0.25231154]]
rvecs : 

(array([[-0.08398729],
       [ 0.34802798],
       [-1.54244125]]), array([[-0.27527313],
       [ 0.10123349],
       [-1.56296568]]), array([[-0.22584613],
       [ 1.0155115 ],
       [-2.79470623]]), array([[ 0.05280128],
       [-0.60171832],
       [-0.18453815]]), array([[-0.10141629],
       [ 0.32034812],
       [ 0.3147293 ]]), array([[-0.34698232],
       [-0.06738512],
       [-1.20088998]]), array([[0.06525918],
       [0.44701842],
       [0.10800013]]), array([[ 0.49542336],
       [ 0.11948808],
       [-0.29675958]]), array([[-0.37463355],
       [ 0.06982818],
       [-0.01937111]]), array([[-0.35339067],
       [ 0.24071863],
       [ 0.20970027]]), array([[-0.4735952 ],
       [ 0.08970834],
       [-0.22605981]]), array([[ 0.19721096],
       [-0.42009963],
       [-0.1949708 ]]), array([[ 0.48287277],
       [-0.17037078],
       [-1.40740327]]))
tvecs : 

(array([[-2.96218417],
       [ 0.57158932],
       [16.83013775]]), array([[-3.99388098],
       [ 2.27704343],
       [12.68878108]]), array([[ 2.53399419],
       [ 4.31999128],
       [13.71919122]]), array([[-2.16838794],
       [-3.50011196],
       [10.73694991]]), array([[-3.72585434],
       [-4.3108485 ],
       [17.20439703]]), array([[-3.427436  ],
       [ 0.4873819 ],
       [11.56153507]]), array([[ 2.20741839],
       [-3.21446613],
       [15.60125394]]), array([[-3.40557514],
       [-2.41042315],
       [12.58706804]]), array([[-2.95848731],
       [-3.94417974],
       [13.21423743]]), array([[-1.59004095],
       [-4.31771235],
       [14.01040668]]), array([[-2.51791826],
       [-3.43069105],
       [12.85702135]]), array([[-2.67642941],
       [-3.18945602],
       [10.58262241]]), array([[-3.50264637],
       [ 1.61595404],
       [11.97222152]]))

</p> 
</code></pre>

<h3>Significados de K, R, t, e dist.</h3>

<h4>A matriz <strong>K</strong></h4>
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
    A matriz <strong>K</strong> de parâmetros intrínsecos da câmera tem o seguinte padrão:
</p> 


<p style="text-align: center; line-height: 1.5;">
<code>
    [[fx    0.    cx]<br>
    [0.    fy    cy]<br>
    [0.    0.    1.]]
    
</code>
</p>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
    Onde fx e fy são as distâncias focais x e y, ou seja, representam o foco da câmera. Os parâmetros cx e cy representam o centro óptico do plano da imagem (geralmente o centro da imagem). O valor zero na primeira linha e segunda coluna da matriz representa a inclinação entre os eixos x e y, geralmente é atribuído o valor zero. Os zeros e o um na terceira linha são convenções da forma homogênea.
</p> 

<h4>A matriz <strong>R</strong> e o vetor <strong>t</strong></h4>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
    Para encontrar a projeção de um ponto 3D no plano da imagem, são necessários os parâmetros extrínsecos (Rotação <strong>R</strong> 3X1 e Translação <strong>t</strong> 3X1). A matriz de rotação <strong>R</strong> representa a rotação do ponto 3D do sistema de coordenadas do mundo (tabuleiro) para o sistema de coordenadas da câmera. O vetor <strong>t</strong> é o vetor translação do sistema de coordenadas do mundo para o sistema de coordenadas da câmera. A rotação no script é especificada como um vetor <strong>r</strong> de 3x1 para cada imagem usada na calibração. Esses vetores são em forma de rotação de Rodrigues, que é uma forma compacta de representar uma matriz de rotação 3x3.
</p> 


<h4>O vetor <strong>d</strong></h4>
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
    São os coeficientes de distorção da lente (termo dist):
</p> 

<p style="text-align: center; line-height: 1.5;">
<code>
    [[ k1 k2  p1  p2  k3]]    
</code>
</p>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
    Onde k1, k2 e k3 representam a distorção radial (faz as linhas retas parecerem curvas); 
    p1 e p2 a Distorção tangencial (causada por desalinhamento da lente com o sensor).
    Esses valores são usados para corrigir as distorções da imagem, muito comum em lentes baratas ou câmeras tipo webcam.
</p> 

<h3 id="-b-leitura-de-v-deo-em-arquivo">(B) Calibração da sua webcam com a captura de suas próprias imagens.</h3>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  As imagens a seguir são resultados do processamento feito pelo programa L2_cal.py aplicado às imagens geradas pelo grupo. Em sequência são mostrados os resultados dos parâmetros calculados.
</p>

<div style="display: flex; justify-content: center; gap: 1px;">
  <img src="/Lab2/Nossas_imagens_resultados_parteA/result1 (1).png" alt="letf01" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_resultados_parteA/result1 (2).png" alt="letf02" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_resultados_parteA/result1 (3).png" alt="letf03" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_resultados_parteA/result1 (4).png" alt="letf04" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_resultados_parteA/result1 (5).png" alt="letf05" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_resultados_parteA/result1 (6).png" alt="letf06" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_resultados_parteA/result1 (7).png" alt="letf07" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_resultados_parteA/result1 (8).png" alt="letf08" width="400" height="200">
</div>

<div style="display: flex; justify-content: center; gap: 1px;">

  <img src="/Lab2/Nossas_imagens_resultados_parteA/result1 (9).png" alt="letf09" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_resultados_parteA/result1 (10).png" alt="letf11" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_resultados_parteA/result1 (11).png" alt="letf12" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_resultados_parteA/result1 (12).png" alt="letf13" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_resultados_parteA/result1 (13).png" alt="letf14" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_resultados_parteA/result1 (14).png" alt="letf14" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_resultados_parteA/result1 (15).png" alt="letf08" width="400" height="200">
</div>

<div style="display: flex; justify-content: center">
  <figcaption>Figura X - Processamento das imagens geradas pelo grupo.</figcaption>
</div>



<pre><code>

 Camera matrix :

[[681.31313572   0.         338.83438339]
 [  0.         680.28102571 237.97905977]
 [  0.           0.           1.        ]]
dist : 

[[ 0.05471118 -0.23836225  0.00204913  0.00131733  0.62389174]]
rvecs : 

(array([[ 0.26322864],
       [-0.34981827],
       [-1.32321508]]), array([[ 0.2116112 ],
       [-0.67845162],
       [ 1.58437346]]), array([[-0.62979673],
       [ 0.16970115],
       [ 0.44629149]]), array([[-0.25428944],
       [-0.37829953],
       [ 1.3569295 ]]), array([[-0.60782013],
       [ 0.20990471],
       [ 1.44878658]]), array([[-0.03930657],
       [ 0.43935939],
       [ 0.07564065]]), array([[-0.01173043],
       [-0.20624347],
       [ 0.04343353]]), array([[ 0.14622958],
       [ 0.00891626],
       [-0.48988343]]), array([[-0.4256197 ],
       [ 0.53447939],
       [ 1.52917068]]), array([[ 0.04103005],
       [-0.61093764],
       [-0.12617062]]), array([[0.17272886],
       [0.13676318],
       [1.54935019]]), array([[-0.57484342],
       [-0.25358952],
       [-0.45894776]]), array([[-0.58606848],
       [-0.24621721],
       [-0.4505711 ]]), array([[-0.22169958],
       [-0.19357459],
       [ 1.45842311]]), array([[-0.10972886],
       [-0.21994229],
       [ 1.50904732]]))
tvecs : 

(array([[-4.33747823],
       [ 2.13449562],
       [12.45723853]]), array([[ 3.40912232],
       [-1.86336858],
       [11.35655984]]), array([[-1.46973137],
       [-4.36037833],
       [17.00324009]]), array([[ 2.71639352],
       [-3.45695725],
       [14.27153313]]), array([[ 2.60284186],
       [-2.54365767],
       [14.75721718]]), array([[-2.83528458],
       [-3.74506818],
       [17.21993768]]), array([[-1.38610851],
       [-3.44676457],
       [14.44166078]]), array([[-3.87938381],
       [-1.42681847],
       [16.6774393 ]]), array([[ 3.14630992],
       [-2.39024673],
       [13.62734449]]), array([[-2.76817882],
       [-3.32759211],
       [14.0338598 ]]), array([[ 2.89324534],
       [-2.60746396],
       [11.08565414]]), array([[-5.23329535],
       [-2.49602871],
       [15.74261591]]), array([[-5.0985607 ],
       [-2.510265  ],
       [15.62759254]]), array([[ 2.91085544],
       [-3.12904553],
       [12.5062273 ]]), array([[ 3.41157859],
       [-2.84304675],
       [12.53109819]]))
</p>
</code></pre>


<h4>Comparação com os resultados obtidos no item anterior</h4>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
Realiza-se a calibração de duas câmeras com o objetivo de extrair seus parâmetros intrínsecos e extrínsecos, além de avaliar as distorções ópticas associadas a cada dispositivo. A comparação considera a matriz intrínseca (K), o vetor de distorção (dist), os vetores de rotação (rvecs) e os vetores de translação (tvecs), obtidos por meio de um processo de calibração com imagens de padrão conhecido.
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
A matriz intrínseca da Câmera 1 apresenta distância focal estimada de aproximadamente 536 unidades em ambos os eixos (fx = 536.07, fy = 536.01). Já a Câmera 2 apresenta valores mais elevados (fx = 681.31, fy = 680.28), representando um aumento de cerca de 27%. Essa diferença indica que a Câmera 2 possui um campo de visão mais estreito e, portanto, uma capacidade de aproximação maior. Os valores do centro óptico (cx, cy) mantêm-se similares entre as duas câmeras, com pequenas variações (cerca de 1%), indicando boa centralização da imagem em ambos os sensores.
A comparação dos vetores de distorção revela características ópticas distintas. A Câmera 1 apresenta uma distorção radial negativa (k₁ = -0.265), característica do tipo barril, enquanto a Câmera 2 exibe uma distorção radial positiva mais branda (k₁ = +0.055), compatível com o tipo almofada. Além disso, o coeficiente de terceira ordem k₃ é significativamente maior na Câmera 2 (k₃ = +0.624), o que indica a presença de distorções de ordem superior mais acentuadas nesse dispositivo. Os coeficientes tangenciais (p₁, p₂) permanecem baixos em ambas as câmeras, sugerindo que a principal distorção ocorre na forma radial.
</p>
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;"></p>
Os vetores de rotação (rvecs) demonstram que ambas as câmeras capturam o padrão de calibração sob diferentes orientações espaciais. A Câmera 1 exibe rotações com maior predominância no eixo z, enquanto a Câmera 2 distribui suas rotações de maneira mais equilibrada entre os três eixos, o que reflete abordagens distintas na aquisição das imagens utilizadas na calibração.
Em relação aos vetores de translação (tvecs), observa-se que ambas as câmeras operam com distâncias semelhantes em relação ao padrão de calibração, variando principalmente entre 10 e 17 unidades no eixo z. No entanto, a Câmera 2 apresenta maior variação nas componentes dos eixos x e y, o que sugere maior diversidade nos ângulos de captura e maior riqueza de pontos de vista.
Conclui-se que, apesar de ambas as câmeras fornecerem resultados consistentes dentro de seus respectivos contextos ópticos, os parâmetros calibrados refletem diferenças significativas em suas características físicas e ópticas. A Câmera 2 evidencia uma lente com maior aproximação (menor campo de visão), maior distorção radial de ordem elevada e variedade de poses de calibração. Já a Câmera 1 apresenta uma distorção mais típica do tipo barril e padrão de aquisição com rotação mais pronunciada sobre um único eixo. Essas diferenças destacam a importância de considerar as particularidades de cada dispositivo óptico na etapa de calibração para garantir precisão na reconstrução tridimensional ou na correção de imagens.
</p>

<h4>Apresente o valor númérico obtido pela calibração de sua câmera dos seguintes parâmetros: focal length, aspect ratio, skew, principal point, e comente esse resultado obtido.</h4>

<h4>Focal lenght</h4>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
fx = 681,31313572 e fy = 680.28102571.
A distância focal representa a relação entre as dimensões físicas da lente e o tamanho dos pixels no sensor, expressa aqui em pixels. Esses valores mostram que a câmera possui resolução uniforme nos eixos horizontal e vertical, com pequena diferença entre fx e fy, o que indica que os pixels são praticamente quadrados. Uma distância focal alta como essa também sugere um campo de visão mais estreito (zoom maior), típico de câmeras com lentes mais fechadas ou com padrão de calibração mais próximo.
</p>

<h4>Aspect ratio</h4>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
aspect_ratio = fx / fy = 681.31313572 / 680.28102571 ≈ 1.0015.
Esse valor está muito próximo de 1, o que indica que o tamanho dos pixels nos eixos x e y é praticamente o mesmo — ou seja, a imagem não sofre distorção por alongamento ou achatamento em nenhum dos eixos. Um aspect ratio diferente de 1 indicaria distorção geométrica intrínseca da imagem.
</p>

<h4>Skew</h4>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
skew = 0.
Esse valor representa o grau de inclinação entre os eixos x e y do sensor. Um skew diferente de zero indicaria que os eixos não são ortogonais (formam um ângulo diferente de 90°), o que poderia ocorrer por imperfeições na montagem do sensor. O valor zero indica que os eixos da imagem estão corretamente perpendiculares, o que é esperado na maioria dos sensores modernos.  
</p>

<h4>Principal point (Centro óptico)</h4>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
cx = 338,83438339, cy = 237,97905977.
Esses valores representam a posição do centro da imagem em coordenadas de pixel. Idealmente, esse ponto coincidiria com o centro geométrico da imagem (largura/2, altura/2), mas na prática há um pequeno deslocamento, o que é comum. Esse deslocamento pode ser causado por leve descentralização da lente em relação ao sensor. A interpretação correta é que o centro óptico projetado no plano da imagem está deslocado de (cx, cy) em relação à origem do sistema de coordenadas da imagem (que geralmente é o canto superior esquerdo). Não se deve dizer que ele está “deslocado do centro óptico da câmera”, pois isso confundiria os conceitos físicos (lente) e projetivos (imagem).
</p>

<h4>Qual o motivo de resultar um conjunto R e t para cada imagem usada na calibração?</h4>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
O motivo é a orientação do tabuleiro de xadrez que é diferente em cada imagem. Desta forma, para cada imagem é calculada a rotação e translação dos pontos 3D no sistema de coordenadas do mundo em relação ao sistema de coordenadas da câmera. 
</p>

<h4>O que estas variáveis R e t significam perante os sistemas de coordenadas envolvidos?</h4>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
O que ocorre no processo de captura da imagem pela câmera é que é calculada uma projeção de um ponto 3D no plano da imagem. Para isso é necessário transformar o ponto do sistema de coordenadas do mundo para o sistema de coordenadas da câmera. Neste contexto temos os parâmetro extrínsecos rotação R e translação t. O sistema de coordenadas do Mundo (tabuleiro de xadrez) está relacionado com o sistema de coordenadas da câmera por uma rotação e uma translação. A rotação é dada por 3 parâmetros, ou seja, deveria ser um vetor de 3 elementos: guinada, inclinação e rotação, porém, é utilizada uma matriz 3x3 para facilitar a matemática da relação entre um ponto no sistema de coordenadas do mundo e o mesmo ponto representado no sistema de coordenadas da câmera. Ao representar a rotação como uma matriz, podemos encontrar a rotação através de uma multiplicação simples de matrizes. Uma vez que obtemos um ponto no sistema de coordenadas 3D da câmera, aplicando uma rotação e translação às coordenadas do mundo dos pontos, estamos em posição de projetar o ponto no plano da imagem para obter uma localização do ponto na imagem.
</p> 

<h3 id="-c-leitura-de-imagem-de-c-mera">(C) Calibração de outra câmera do laboratório</h3>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  As imagens a seguir são resultados do processamento feito pelo programa L2_cal.py aplicado às imagens geradas pelo grupo na câmera de maior distorção. Em sequência são mostrados os resultados dos parâmetros calculados.
</p>

<div style="display: flex; justify-content: center; gap: 1px;">
  <img src="/Lab2/Nossas_imagens_parte_C_resultados/resultados(2).png" alt="letf01" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_parte_C_resultados/resultados(3).png" alt="letf01" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_parte_C_resultados/resultados(4).png" alt="letf01" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_parte_C_resultados/resultados(5).png" alt="letf01" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_parte_C_resultados/resultados(6).png" alt="letf01" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_parte_C_resultados/resultados(7).png" alt="letf01" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_parte_C_resultados/resultados(8).png" alt="letf01" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_parte_C_resultados/resultados(9).png" alt="letf01" width="400" height="200">
</div>

<div style="display: flex; justify-content: center; gap: 1px;">
  <img src="/Lab2/Nossas_imagens_parte_C_resultados/resultados(10).png" alt="letf01" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_parte_C_resultados/resultados(11).png" alt="letf01" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_parte_C_resultados/resultados(12).png" alt="letf01" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_parte_C_resultados/resultados(13).png" alt="letf01" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_parte_C_resultados/resultados(14).png" alt="letf01" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_parte_C_resultados/resultados(15).png" alt="letf01" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_parte_C_resultados/resultados(16).png" alt="letf01" width="400" height="200">
  <img src="/Lab2/Nossas_imagens_parte_C_resultados/resultados(17).png" alt="letf01" width="400" height="200">
</div>

<div style="display: flex; justify-content: center">
  <figcaption>Figura X - Processamento das imagens geradas pelo grupo com câmera de maior distorção..</figcaption>
</div>

<pre><code>
Camera matrix : 

[[588.061213     0.         322.57638831]
 [  0.         588.20498337 247.43327418]
 [  0.           0.           1.        ]]
dist : 

[[-3.94639155e-01  3.88505575e-01 -9.11347576e-04  2.88161247e-04
  -6.15711484e-01]]
rvecs : 

(array([[-0.42381565],
       [ 0.18602803],
       [ 1.36352981]]), array([[-0.13537295],
       [ 0.0103217 ],
       [ 0.69421391]]), array([[-0.2091288 ],
       [ 0.06540522],
       [ 1.03925791]]), array([[-0.20098521],
       [-0.01547093],
       [ 1.57343334]]), array([[-0.25398874],
       [-0.23916685],
       [-1.24808924]]), array([[-0.15324038],
       [-0.08513321],
       [-0.99705745]]), array([[ 0.0210668],
       [-0.1639967],
       [ 0.008342 ]]), array([[0.10258857],
       [0.37449714],
       [1.56303189]]), array([[-0.09171344],
       [-0.2147489 ],
       [-0.61110772]]), array([[-0.46346808],
       [-0.25024253],
       [ 1.48278525]]), array([[-0.38136412],
       [-0.36975439],
       [ 1.48623405]]), array([[0.53808104],
       [0.7464011 ],
       [1.47652293]]), array([[-0.43458938],
       [-0.63980879],
       [-1.47844253]]), array([[ 0.18889047],
       [-0.46269803],
       [-1.44698918]]), array([[ 0.33946917],
       [-0.66150471],
       [ 1.58206492]]), array([[ 0.33223252],
       [-0.59626991],
       [ 1.59085073]]))
tvecs : 

(array([[ 3.45080221],
       [-3.42803627],
       [12.0962708 ]]), array([[ 2.10091337],
       [-5.01656747],
       [15.03467777]]), array([[ 2.61012626],
       [-4.36812285],
       [14.06821609]]), array([[ 3.90266188],
       [-2.58413142],
       [11.6986545 ]]), array([[-2.71508814],
       [ 0.60294952],
       [10.72053887]]), array([[-2.85872128],
       [-0.71741432],
       [13.43184449]]), array([[-2.16876742],
       [-3.47183993],
       [11.41850321]]), array([[ 3.14111827],
       [-2.79792749],
       [ 9.42536904]]), array([[-1.85509934],
       [-1.72783005],
       [13.91120073]]), array([[ 3.63869764],
       [-2.84266505],
       [12.30349164]]), array([[ 2.72162072],
       [-3.02299477],
       [11.53568354]]), array([[ 2.66406183],
       [-2.42819361],
       [ 9.66006176]]), array([[-2.41316349],
       [ 1.14174974],
       [ 9.84747585]]), array([[-1.11709926],
       [ 1.95642534],
       [ 9.16507106]]), array([[ 3.70250962],
       [-1.58357202],
       [ 8.78719727]]), array([[ 4.72244519],
       [-1.86198736],
       [11.75868821]]))
</p>
</code></pre>
    
<h3 id="-d-grava-o-de-v-deo-da-c-mera">(D) Correção de distorção de imagens.</h3>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  Para correções de distorções nas imagens utilizamos o seguinte script:
</p>

<pre>
<code class="language-python">

import cv2
import numpy as np
import glob

# === PARÂMETROS DA CÂMERA COM DISTORÇÃO ===
K = np.array([[588.061213, 0., 322.57638831],
              [0., 588.20498337, 247.43327418],
              [0., 0., 1.]])

dist = np.array([[-0.39463915, 0.38850557, -0.00091135, 0.00028816, -0.61571148]])

# === OPÇÃO: caminho para as imagens capturadas com essa câmera ===
image_files = glob.glob("distorcida/*.jpg")  # coloque suas imagens na pasta "distorcida/"

# === CRIA A PASTA DE SAÍDA SE NÃO EXISTIR ===
import os
os.makedirs("corrigida", exist_ok=True)

for fname in image_files:
    img = cv2.imread(fname)
    h, w = img.shape[:2]

    # Cálculo da nova matriz da câmera (corrigida)
    new_K, roi = cv2.getOptimalNewCameraMatrix(K, dist, (w,h), alpha=1, centerPrincipalPoint=True)

    # Corrige a distorção
    undistorted = cv2.undistort(img, K, dist, None, new_K)

    # (Opcional) Recorte para remover áreas pretas
    x, y, w, h = roi
    undistorted = undistorted[y:y+h, x:x+w]

    # Salvar imagem corrigida
    name = os.path.basename(fname)
    cv2.imwrite(f"corrigida/corrigida_{name}", undistorted)
    print(f"Corrigida: {name}")

print("\n✅ Todas as imagens foram corrigidas e salvas na pasta 'corrigida/'")
</code>
</pre>


<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  As imagens a seguir mostram os resultados das correções das distorções. Do lado esquerdo as imagens originais e do lado direito as imagens corrigidas.
</p>

<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab2/ParteD/Jorge16.jpg" alt="letf01" width="600" height="300"> 
  <img src="/Lab2/ParteD/corrigida/corrigida_Jorge16.jpg" alt="letf01" width="600" height="300">
</div>

<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab2/ParteD/Jorge17.jpg" alt="letf01" width="600" height="300">
  <img src="/Lab2/ParteD/corrigida/corrigida_Jorge17.jpg" alt="letf01" width="600" height="300">
</div>

<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab2/ParteD/Jorge18.jpg" alt="letf01" width="600" height="300">
  <img src="/Lab2/ParteD/corrigida/corrigida_Jorge18.jpg" alt="letf01" width="600" height="300">
</div>

<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab2/ParteD/Jorge19.jpg" alt="letf01" width="600" height="300">
  <img src="/Lab2/ParteD/corrigida/corrigida_Jorge19.jpg" alt="letf01" width="600" height="300">
</div>

<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab2/ParteD/Jorge20.jpg" alt="letf01" width="600" height="300">
  <img src="/Lab2/ParteD/corrigida/corrigida_Jorge20.jpg" alt="letf01" width="600" height="300">
</div>

<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab2/ParteD/Jorge21.jpg" alt="letf01" width="600" height="300">
  <img src="/Lab2/ParteD/corrigida/corrigida_Jorge21.jpg" alt="letf01" width="600" height="300">
</div>

<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab2/ParteD/Jorge22.jpg" alt="letf01" width="600" height="300">
  <img src="/Lab2/ParteD/corrigida/corrigida_Jorge22.jpg" alt="letf01" width="600" height="300">
</div>

<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab2/ParteD/Jorge23.jpg" alt="letf01" width="600" height="300">
  <img src="/Lab2/ParteD/corrigida/corrigida_Jorge23.jpg" alt="letf01" width="600" height="300">
</div>

<div style="display: flex; justify-content: center">
  <figcaption>Figura X - Resultados parte D.</figcaption>
</div>

<section>
  <h2>Processo de Calibração da Câmera</h2>

  <p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
    A calibração de câmera é uma etapa fundamental em aplicações de Visão Computacional, como reconstrução 3D,
    realidade aumentada e medição de distâncias. Seu principal objetivo é encontrar os parâmetros que descrevem
    matematicamente como a câmera transforma pontos do mundo real (3D) em pontos na imagem (2D).
  </p>

  <h3>1. Captura das Imagens com Tabuleiro de Xadrez</h3>
  <p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
    Foram capturadas diversas imagens de um padrão conhecido — um tabuleiro de xadrez — posicionadas sob diferentes
    ângulos e distâncias em relação à câmera. Esse padrão foi escolhido por apresentar cantos bem definidos e regularmente espaçados, ideais para detecção automática.
  </p>

  <h3>2. Detecção de Cantos</h3>
 <p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
    Em cada imagem, foi utilizado o algoritmo <code>cv2.findChessboardCorners()</code> para localizar automaticamente
    os cantos internos do tabuleiro. Em seguida, a função <code>cv2.cornerSubPix()</code> foi aplicada para refinar a posição desses
    cantos com precisão subpixel.
  </p>

  <h3>3. Associação de Pontos 3D ↔ 2D</h3>
  <p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
    Para cada imagem foram associados:
    <ul>
      <li><strong>Pontos 3D:</strong> Coordenadas reais dos cantos no plano do tabuleiro (com Z = 0), definidas em um sistema de coordenadas arbitrário.</li>
      <li><strong>Pontos 2D:</strong> Coordenadas dos pixels onde os cantos foram detectados na imagem.</li>
    </ul>
    Essa correspondência foi utilizada como base para estimar os parâmetros da câmera.
  </p>

  <h3>4. Cálculo dos Parâmetros com <code>cv2.calibrateCamera()</code></h3>
  <p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
    A função <code>cv2.calibrateCamera()</code> foi utilizada para estimar os seguintes parâmetros:
  </p>

  <ul>
    <li>
      <strong>Matriz Intrínseca (K):</strong> Representa as propriedades internas da câmera, como:
      <ul>
        <li>Distâncias focais em pixels (<code>fx</code>, <code>fy</code>)</li>
        <li>Coordenadas do centro óptico da imagem (<code>cx</code>, <code>cy</code>)</li>
      </ul>
      <pre>
K = | fx  0  cx |
    | 0  fy  cy |
    | 0   0   1 |
      </pre>
    </li>

    <li>
      <strong>Coeficientes de Distorção:</strong> Utilizados para modelar e corrigir imperfeições ópticas da lente, incluindo distorção radial e tangencial.
      <pre>
dist = [k1, k2, p1, p2, k3]
      </pre>
    </li>

    <li>
      <strong>Vetores de Rotação (rvecs):</strong> Representam a orientação da câmera em relação ao tabuleiro em cada imagem capturada.
    </li>
    <li>
      <strong>Vetores de Translação (tvecs):</strong> Representam a posição da câmera em relação ao plano do tabuleiro.
    </li>
  </ul>

  <h3>5. Correção da Distorção (Undistortion)</h3>
  <p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
    Após a calibração, foi possível corrigir as distorções nas imagens aplicando a função <code>cv2.undistort()</code>.
    Essa etapa remove os efeitos ópticos indesejados e aproxima a imagem da sua geometria real.
  </p>

  <h3>6. Aplicações Práticas</h3>
  <p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
    A calibração permite:
    <ul>
      <li>Corrigir distorções em imagens capturadas</li>
      <li>Realizar medições precisas de distância e ângulos</li>
      <li>Projetar corretamente objetos virtuais em imagens reais (realidade aumentada)</li>
      <li>Estimar a pose da câmera no espaço tridimensional</li>
    </ul>
  </p>


<h2 id="conclus-o">Conclusão</h2>
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
A respeito da parte A e da parte B e suas comparações conclui-se que os parâmetros obtidos indicam uma calibração consistente e compatível com sensores de qualidade. O valor do aspect ratio próximo de 1 confirma que os pixels do sensor possuem proporções praticamente quadradas, o que garante uniformidade na escala dos eixos e favorece aplicações que assumem simetria na resolução. O valor nulo do skew revela que os eixos da imagem são ortogonais, o que é desejável e caracteriza uma montagem precisa do sensor da câmera. Além disso, o pequeno deslocamento do principal point em relação ao centro da imagem é esperado na prática e não compromete os resultados da calibração. A proximidade entre os valores de fx e fy também sugere uma boa uniformidade entre os eixos horizontal e vertical, o que simplifica o uso desses parâmetros em aplicações como reconstrução tridimensional, visão estéreo e correção de distorção.
</p>

<h3>Referências</h3>
  <p>
    O procedimento segue o algoritmo de Zhang para calibração de câmeras, conforme implementado na biblioteca OpenCV.
    <a href="https://docs.opencv.org/4.x/dc/dbb/tutorial_py_calibration.html" target="_blank">Documentação oficial do OpenCV</a>.
  </p>
</section>
  
