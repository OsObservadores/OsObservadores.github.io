<head>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>
</head>

<h1 id="relat-rio-laborat-rio-1">Relatório Laboratório 3 - Câmeras Estéreo</h1>
<p>Jorge Luiz Pinto Junior  - RA: 11058715 - CEO</p>
<p>Marcos Baldrigue Andrade - RA: 11201921777 - CFO - Financeiro</p>
<p>Guilherme Eduardo Pereira - RA: 11201720498 - CPO - Desenvolvimento</p>
<p>Data de realização do experimento: 02/07/2025</p>
<p>Data de publicação do relatório: 21/07/2025</p>
<h2 id="introdu-o">Introdução</h2>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
O presente relatório tem como objetivo apresentar o estudo e a aplicação prática de conceitos fundamentais relacionados à visão computacional. Inicialmente, compreende-se os princípios teóricos de Estereoscopia e Geometria Epipolar, que fornecem a base para a análise de imagens captadas por sistemas de câmeras estéreo. Em seguida, realiza-se um experimento de imagem tridimensional (3D) por meio da calibração de câmeras estéreo, a fim de validar os conceitos abordados e observar, de forma prática, a reconstrução de cenas em três dimensões. Por fim, elabora-se este relatório em equipe, integrando os resultados obtidos, a análise dos procedimentos adotados e a reflexão sobre o aprendizado adquirido ao longo do desenvolvimento do trabalho.
</p> 

<h2 id="procedimentos-experimentais">Procedimentos Experimentais</h2>

<h3 id="-parte-1">PARTE 1 - Estudo da teoria.</h3>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
Foram apresentados os seguintes links com o conteúdo a ser estudado para execução do experimento: <strong>Link 1:</strong> <a href="https://learnopencv.com/introduction-to-epipolar-geometry-and-stereo-vision/" target="_blank">
    Introduction to Epipolar Geometry and Stereo Vision
  </a>
 e <strong>Link 2:</strong> <a href="https://learnopencv.com/making-a-low-cost-stereo-camera-using-opencv/" target="_blank">
        Making a Low-Cost Stereo Camera Using OpenCV
  </a>.
  </p> 

<h3 id="-parte-2">PARTE 2 - Construção de uma câmera estereoscópica simples.</h3>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
Foram fornecidas duas câmeras identicas no laboratório. As duas câmeras foram fixadas em uma prancheta, lado a lado, de tal forma que o centro das lentes do óculos 3D vermelho-ciano coincidiam com o centro da lente de cada câmera.
</p>

<h3 id="-parte-3">PARTE 3 - Calibração de uma câmera estereoscópica e geração de imagem 3D.</h3>

<h3 id="-a-leitura-de-imagem-em-arquivo">(A) Obtenção dos códigos do exemplo da câmera estéreo com OpenCV.</h3>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
Os códigos utilizados para o experimento foram retirados do seguinte repositório: <strong>Link:</strong><a href="https://github.com/spmallick/learnopencv/tree/master/stereo-camera" target="_blank">
    Stereo-camera.
  </a>
</p> 

<h3 id="-b-leitura-de-v-deo-em-arquivo">(B) Exemplo com imagens fornecidas.</h3>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  Para realização desta etapa, foram fornecidas imagens tiradas de uma câmera estereoscópica (junção de duas câmeras iguais) desconhecida. As imagens para cada câmera foram geradas ao mesmo tempo. E através destas, foram calibradas as duas câmeras (lado direito e lado esquerdo). A seguir são apresentadas as imagens fornecidas, onde a imagem a esquerda provém da primeira câmera e a imagem a direita da segunda câmera.
</p>

<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/stereoL_old/img1.png" alt="letf01" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/stereoR_old/img1.png" alt="right01" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/stereoL_old/img2.png" alt="letf02" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/stereoR_old/img2.png" alt="right02" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/stereoL_old/img3.png" alt="letf03" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/stereoR_old/img3.png" alt="right03" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/stereoL_old/img4.png" alt="letf04" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/stereoR_old/img4.png" alt="right04" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/stereoL_old/img5.png" alt="left05" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/stereoR_old/img5.png" alt="right05" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/stereoL_old/img6.png" alt="left06" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/stereoR_old/img6.png" alt="right06" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/stereoL_old/img7.png" alt="letf07" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/stereoR_old/img7.png" alt="right07" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/stereoL_old/img8.png" alt="left08" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/stereoR_old/img8.png" alt="right08" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/stereoL_old/img9.png" alt="letf09" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/stereoR_old/img9.png" alt="right09" width="400" height="200">
</div>

<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/stereoL_old/img10.png" alt="letf10" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/stereoR_old/img10.png" alt="right10" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/stereoL_old/img11.png" alt="letf11" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/stereoR_old/img11.png" alt="right11" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/stereoL_old/img12.png" alt="letf12" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/stereoR_old/img12.png" alt="right12" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/stereoL_old/img13.png" alt="letf13" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/stereoR_old/img13.png" alt="right13" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/stereoL_old/img14.png" alt="letf14" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/stereoR_old/img14.png" alt="right14" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/stereoL_old/img15.png" alt="left15" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/stereoR_old/img15.png" alt="right15" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/stereoL_old/img16.png" alt="left16" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/stereoR_old/img16.png" alt="right16" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/stereoL_old/img17.png" alt="letf17" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/stereoR_old/img17.png" alt="right17" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/stereoL_old/img18.png" alt="left18" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/stereoR_old/img18.png" alt="right18" width="400" height="200">
</div>


<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/stereoL_old/img19.png" alt="letf19" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/stereoR_old/img19.png" alt="right19" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/stereoL_old/img20.png" alt="letf20" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/stereoR_old/img20.png" alt="right20" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/stereoL_old/img21.png" alt="letf21" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/stereoR_old/img21.png" alt="right21" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/stereoL_old/img22.png" alt="letf22" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/stereoR_old/img22.png" alt="right22" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/stereoL_old/img23.png" alt="left23" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/stereoR_old/img23.png" alt="right23" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/stereoL_old/img24.png" alt="left24" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/stereoR_old/img24.png" alt="right24" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/stereoL_old/img25.png" alt="letf25" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/stereoR_old/img25.png" alt="right25" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/stereoL_old/img26.png" alt="left26" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/stereoR_old/img26.png" alt="right26" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/stereoL_old/img27.png" alt="letf27" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/stereoR_old/img27.png" alt="right27" width="400" height="200">
</div>
<div style="display: flex; justify-content: center">
  <figcaption>Figura 1 - Imagens fornecidas para calibração.</figcaption>
</div>
  

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
Inicialmente, realiza-se a calibração individual de cada câmera por meio do método de calibração OpenCV. Em seguida, determina-se a transformação entre as duas câmeras configuradas no sistema estéreo. Com os parâmetros obtidos, emprega-se o método <strong>stereoCalibrate</strong> para calcular as transformações necessárias à retificação estéreo. A partir disso, utiliza-se o método <strong>initUndistortRectifyMap</strong> para gerar o mapeamento que corrige distorções e prepara as imagens para retificação. Por fim, aplica-se esse mapeamento às imagens originais, obtendo-se um par estéreo retificado e livre de distorções.
</p>
<h3 id="-b-leitura-de-v-deo-em-arquivo">Método para obter o par de imagens estéreo:</h3>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  O script a seguir realiza as quatro etapas descritas acima: calibração das câmeras individuais, calibração estéreo com parâmetros intrínsecos fixos, retificação estéreo e por fim o mapeamento que obtém o par de imagens estéreo retificadas e sem distorções.</p>

<pre><code class="language-python">
import numpy as np 
import cv2
from tqdm import tqdm

# Set the path to the images captured by the left and right cameras
pathL = "/home/jorge/Documentos/cv2025/lab3/Lab3_Camera_3D/stereo-camera/data/stereoL_old"
pathR = "/home/jorge/Documentos/cv2025/lab3/Lab3_Camera_3D/stereo-camera/data/stereoR_old"

print("Extracting image coordinates of respective 3D pattern ....\n")

# Termination criteria for refining the detected corners
criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)


objp = np.zeros((9*6,3), np.float32)
objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)

img_ptsL = []
img_ptsR = []
obj_pts = []

for i in tqdm(range(1,27)):
	imgL = cv2.imread('/home/jorge/Documentos/cv2025/lab3/Lab3_Camera_3D/stereo-camera/data/stereoL_old/img%d.png'%i)
	imgR = cv2.imread('/home/jorge/Documentos/cv2025/lab3/Lab3_Camera_3D/stereo-camera/data/stereoR_old/img%d.png'%i)
	imgL_gray = cv2.imread('/home/jorge/Documentos/cv2025/lab3/Lab3_Camera_3D/stereo-camera/data/stereoL_old/img%d.png'%i,0)
	imgR_gray = cv2.imread('/home/jorge/Documentos/cv2025/lab3/Lab3_Camera_3D/stereo-camera/data/stereoR_old/img%d.png'%i,0)

	outputL = imgL.copy()
	outputR = imgR.copy()

	retR, cornersR =  cv2.findChessboardCorners(outputR,(9,6),None)
	retL, cornersL = cv2.findChessboardCorners(outputL,(9,6),None)

	if retR and retL:
		obj_pts.append(objp)
		cv2.cornerSubPix(imgR_gray,cornersR,(11,11),(-1,-1),criteria)
		cv2.cornerSubPix(imgL_gray,cornersL,(11,11),(-1,-1),criteria)
		cv2.drawChessboardCorners(outputR,(9,6),cornersR,retR)
		cv2.drawChessboardCorners(outputL,(9,6),cornersL,retL)
		cv2.imshow('cornersR',outputR)
		cv2.imshow('cornersL',outputL)
		cv2.waitKey(0)

		img_ptsL.append(cornersL)
		img_ptsR.append(cornersR)


print("Calculating left camera parameters ... ")
# Calibrating left camera
retL, mtxL, distL, rvecsL, tvecsL = cv2.calibrateCamera(obj_pts,img_ptsL,imgL_gray.shape[::-1],None,None)
hL,wL= imgL_gray.shape[:2]
new_mtxL, roiL= cv2.getOptimalNewCameraMatrix(mtxL,distL,(wL,hL),1,(wL,hL))

print("Calculating right camera parameters ... ")
# Calibrating right camera
retR, mtxR, distR, rvecsR, tvecsR = cv2.calibrateCamera(obj_pts,img_ptsR,imgR_gray.shape[::-1],None,None)
hR,wR= imgR_gray.shape[:2]
new_mtxR, roiR= cv2.getOptimalNewCameraMatrix(mtxR,distR,(wR,hR),1,(wR,hR))


print("Stereo calibration .....")
flags = 0
flags |= cv2.CALIB_FIX_INTRINSIC
# Here we fix the intrinsic camara matrixes so that only Rot, Trns, Emat and Fmat are calculated.
# Hence intrinsic parameters are the same 

criteria_stereo= (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)


# This step is performed to transformation between the two cameras and calculate Essential and Fundamenatl matrix
retS, new_mtxL, distL, new_mtxR, distR, Rot, Trns, Emat, Fmat = cv2.stereoCalibrate(obj_pts,
                                                          img_ptsL,
                                                          img_ptsR,
                                                          new_mtxL,
                                                          distL,
                                                          new_mtxR,
                                                          distR,
                                                          imgL_gray.shape[::-1],
                                                          criteria_stereo,
                                                          flags)

# Once we know the transformation between the two cameras we can perform stereo rectification
# StereoRectify function
rectify_scale= 1 # if 0 image croped, if 1 image not croped
rect_l, rect_r, proj_mat_l, proj_mat_r, Q, roiL, roiR= cv2.stereoRectify(new_mtxL, distL, new_mtxR, distR,
                                                 imgL_gray.shape[::-1], Rot, Trns,
                                                 rectify_scale,(0,0))

# Use the rotation matrixes for stereo rectification and camera intrinsics for undistorting the image
# Compute the rectification map (mapping between the original image pixels and 
# their transformed values after applying rectification and undistortion) for left and right camera frames
Left_Stereo_Map= cv2.initUndistortRectifyMap(new_mtxL, distL, rect_l, proj_mat_l,
                                             imgL_gray.shape[::-1], cv2.CV_16SC2)
Right_Stereo_Map= cv2.initUndistortRectifyMap(new_mtxR, distR, rect_r, proj_mat_r,
                                              imgR_gray.shape[::-1], cv2.CV_16SC2)


print("Saving paraeters ......")
cv_file = cv2.FileStorage("/home/jorge/Documentos/cv2025/lab3/Lab3_Camera_3D/stereo-camera/data/params_nossas_fotos2_py.xml", cv2.FILE_STORAGE_WRITE)
cv_file.write("Left_Stereo_Map_x",Left_Stereo_Map[0])
cv_file.write("Left_Stereo_Map_y",Left_Stereo_Map[1])
cv_file.write("Right_Stereo_Map_x",Right_Stereo_Map[0])
cv_file.write("Right_Stereo_Map_y",Right_Stereo_Map[1])
cv_file.release()
</code></pre>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  O resultado da execução do script acima é mostrado na sessão <strong>"Análise dos resultados"</strong>.
</p>

<h3 id="-c-leitura-de-imagem-de-c-mera">(C) Execute a calibração da sua câmera estéreo (contruída com as webcams) pela captura de suas próprias imagens de calibração e imagens de teste:</h3>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
 As imagens a seguir foram obtidas utilizando o programa <strong>L1_3_webcam.py</strong> utilizado no laboratório 1. O script é mostrado logo após as imagens. 
</p>

<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_C/stereoL/img1.png" alt="letf01" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_C/stereoR/img1.png" alt="right01" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_C/stereoL/img2.png" alt="letf02" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_C/stereoR/img2.png" alt="right02" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_C/stereoL/img3.png" alt="letf03" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_C/stereoR/img3.png" alt="right03" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_C/stereoL/img4.png" alt="letf04" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_C/stereoR/img4.png" alt="right04" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_C/stereoL/img5.png" alt="left05" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_C/stereoR/img5.png"alt="right05" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_C/stereoL/img6.png" alt="left06" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_C/stereoR/img6.png" alt="right06" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_C/stereoL/img7.png" alt="left08" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_C/stereoR/img7.png" alt="right08" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_C/stereoL/img8.png" alt="letf09" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_C/stereoR/img8.png" alt="right09" width="400" height="200">
</div>

<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_C/stereoL/img9.png" alt="letf10" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_C/stereoR/img9.png" alt="right10" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_C/stereoL/img10.png" alt="letf11" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_C/stereoR/img10.png" alt="right11" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_C/stereoL/img11.png" alt="letf12" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_C/stereoR/img11.png" alt="right12" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_C/stereoL/img12.png" alt="letf13" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_C/stereoR/img12.png"  alt="right13" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_C/stereoL/img13.png" alt="letf14" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_C/stereoR/img13.png"  alt="right14" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_C/stereoL/img14.png" alt="left15" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_C/stereoR/img14.png"  alt="right15" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_C/stereoL/img16.png" alt="left16" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_C/stereoR/img16.png"  alt="right16" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_C/stereoL/img17.png" alt="left15" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_C/stereoR/img17.png"  alt="right15" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_C/stereoL/img18.png" alt="left16" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_C/stereoR/img18.png"  alt="right16" width="400" height="200">
</div>

<pre><code class="language-python">
import numpy as np
import cv2 as cv

cap = cv.VideoCapture(0)

if not cap.isOpened():
    print("Cannot open camera")
    exit()
    
while True:
    # Capture frame-by-frame
    ret, frame = cap.read()
    # if frame is read correctly ret is True
    if not ret:
        print("Can't receive frame (stream end?). Exiting ...")
        break
    
    # Display the resulting frame
    cv.imshow('frame', frame)
 
    if cv.waitKey(1) == ord('x'):
        cv.imwrite('foto1.png',frame)  
    
    if cv.waitKey(1) == ord('q'):
        break      
# When everything done, release the capture
cap.release()
cv.destroyAllWindows()
</code></pre>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  Em posse das imagens geradas pelas nossa câmeras, utilizamos o programa <strong>calibrate_parteC.py</strong> mostrado a seguir:
</p>

<pre><code class="language-python">
import numpy as np 
import cv2
from tqdm import tqdm

# Set the path to the images captured by the left and right cameras
pathL = "/home/jorge/Documentos/cv2025/lab3/Lab3_Camera_3D/stereo-camera/data/stereoL"
pathR = "/home/jorge/Documentos/cv2025/lab3/Lab3_Camera_3D/stereo-camera/data/stereoR"

print("Extracting image coordinates of respective 3D pattern ....\n")

# Termination criteria for refining the detected corners
criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)


objp = np.zeros((8*6,3), np.float32)
objp[:,:2] = np.mgrid[0:8,0:6].T.reshape(-1,2)

img_ptsL = []
img_ptsR = []
obj_pts = []

for i in tqdm(range(1,27)):
	imgL = cv2.imread('/home/jorge/Documentos/cv2025/lab3/Lab3_Camera_3D/stereo-camera/data/stereoL/img%d.png'%i)
	imgR = cv2.imread('/home/jorge/Documentos/cv2025/lab3/Lab3_Camera_3D/stereo-camera/data/stereoR/img%d.png'%i)
	imgL_gray = cv2.imread('/home/jorge/Documentos/cv2025/lab3/Lab3_Camera_3D/stereo-camera/data/stereoL/img%d.png'%i,0)
	imgR_gray = cv2.imread('/home/jorge/Documentos/cv2025/lab3/Lab3_Camera_3D/stereo-camera/data/stereoR/img%d.png'%i,0)

	outputL = imgL.copy()
	outputR = imgR.copy()

	retR, cornersR =  cv2.findChessboardCorners(outputR,(8,6),None)
	retL, cornersL = cv2.findChessboardCorners(outputL,(8,6),None)

	if retR and retL:
		obj_pts.append(objp)
		cv2.cornerSubPix(imgR_gray,cornersR,(11,11),(-1,-1),criteria)
		cv2.cornerSubPix(imgL_gray,cornersL,(11,11),(-1,-1),criteria)
		cv2.drawChessboardCorners(outputR,(8,6),cornersR,retR)
		cv2.drawChessboardCorners(outputL,(8,6),cornersL,retL)
		cv2.imshow('cornersR',outputR)
		cv2.imshow('cornersL',outputL)
		cv2.waitKey(0)

		img_ptsL.append(cornersL)
		img_ptsR.append(cornersR)


print("Calculating left camera parameters ... ")
# Calibrating left camera
retL, mtxL, distL, rvecsL, tvecsL = cv2.calibrateCamera(obj_pts,img_ptsL,imgL_gray.shape[::-1],None,None)
hL,wL= imgL_gray.shape[:2]
new_mtxL, roiL= cv2.getOptimalNewCameraMatrix(mtxL,distL,(wL,hL),1,(wL,hL))

print("Calculating right camera parameters ... ")
# Calibrating right camera
retR, mtxR, distR, rvecsR, tvecsR = cv2.calibrateCamera(obj_pts,img_ptsR,imgR_gray.shape[::-1],None,None)
hR,wR= imgR_gray.shape[:2]
new_mtxR, roiR= cv2.getOptimalNewCameraMatrix(mtxR,distR,(wR,hR),1,(wR,hR))


print("Stereo calibration .....")
flags = 0
flags |= cv2.CALIB_FIX_INTRINSIC
# Here we fix the intrinsic camara matrixes so that only Rot, Trns, Emat and Fmat are calculated.
# Hence intrinsic parameters are the same 

criteria_stereo= (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)


# This step is performed to transformation between the two cameras and calculate Essential and Fundamenatl matrix
retS, new_mtxL, distL, new_mtxR, distR, Rot, Trns, Emat, Fmat = cv2.stereoCalibrate(obj_pts,
                                                          img_ptsL,
                                                          img_ptsR,
                                                          new_mtxL,
                                                          distL,
                                                          new_mtxR,
                                                          distR,
                                                          imgL_gray.shape[::-1],
                                                          criteria_stereo,
                                                          flags)

# Once we know the transformation between the two cameras we can perform stereo rectification
# StereoRectify function
rectify_scale= 1 # if 0 image croped, if 1 image not croped
rect_l, rect_r, proj_mat_l, proj_mat_r, Q, roiL, roiR= cv2.stereoRectify(new_mtxL, distL, new_mtxR, distR,
                                                 imgL_gray.shape[::-1], Rot, Trns,
                                                 rectify_scale,(0,0))

# Use the rotation matrixes for stereo rectification and camera intrinsics for undistorting the image
# Compute the rectification map (mapping between the original image pixels and 
# their transformed values after applying rectification and undistortion) for left and right camera frames
Left_Stereo_Map= cv2.initUndistortRectifyMap(new_mtxL, distL, rect_l, proj_mat_l,
                                             imgL_gray.shape[::-1], cv2.CV_16SC2)
Right_Stereo_Map= cv2.initUndistortRectifyMap(new_mtxR, distR, rect_r, proj_mat_r,
                                              imgR_gray.shape[::-1], cv2.CV_16SC2)


print("Saving paraeters ......")
cv_file = cv2.FileStorage("/home/jorge/Documentos/cv2025/lab3/Lab3_Camera_3D/stereo-camera/data/params_nossas_fotos2_py.xml", cv2.FILE_STORAGE_WRITE)
cv_file.write("Left_Stereo_Map_x",Left_Stereo_Map[0])
cv_file.write("Left_Stereo_Map_y",Left_Stereo_Map[1])
cv_file.write("Right_Stereo_Map_x",Right_Stereo_Map[0])
cv_file.write("Right_Stereo_Map_y",Right_Stereo_Map[1])
cv_file.release()
</code></pre>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  Os resultados da execução do script acima são mostrados na sessão <strong>"Análise dos resultados"</strong>.
</p>

<h3 id="-d-grava-o-de-v-deo-da-c-mera">(D) Realize a gravação de um vídeo 3D com sua câmera estéreo.</h3>


<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  Para criar um vídeo em 3D, primeiramente foi feita a captura dos vídeos utilizando o script abaixo:
</p>

<pre><code class="language-python">
Captura de videos:

import numpy as np
import cv2 as cv
import os

# Certifique-se de que o diretório existe
output_dir = os.path.expanduser('~/data_you/')
os.makedirs(output_dir, exist_ok=True)

# Inicializa as câmeras
capL = cv.VideoCapture(0)
capR = cv.VideoCapture(2)

# Verifica se ambas as câmeras foram abertas com sucesso
if not capL.isOpened():
    print("Não foi possível abrir a câmera esquerda (capL)")
    exit()

if not capR.isOpened():
    print("Não foi possível abrir a câmera direita (capR)")
    exit()

# Obtém as propriedades das câmeras (usa a da esquerda como base)
width = int(capL.get(cv.CAP_PROP_FRAME_WIDTH))
height = int(capL.get(cv.CAP_PROP_FRAME_HEIGHT))
fps = 20.0

while True:
    # Captura os frames de ambas as câmeras
    retL, frameL = capL.read()
    retR, frameR = capR.read()

    if not retL or not retR:
        print("Erro ao capturar frames. Encerrando...")
        break


    # Exibe os vídeos em janelas separadas
    cv.imshow('frameL', frameL)
    cv.imshow('frameR', frameR)

    # Sai com 'q'
    if cv.waitKey(1) == ord('q'):
        break

# Libera tudo
#capL.release()
#capR.release()
#cv.destroyAllWindows()

fourcc = cv.VideoWriter_fourcc(*'XVID')
outL = cv.VideoWriter('stereoL.avi', fourcc, fps, (width, height))
outR = cv.VideoWriter('stereoR.avi', fourcc, fps, (width, height))

while capL.isOpened():
    retL, frameL = capL.read()
    retR, frameR = capR.read()
    if not retL:
        print("Can't receive frame (stream end?). Exiting ...")
        break
    # write the flipped frame
    outL.write(frameL)
    outR.write(frameR)
    cv.imshow('frameL', frameL)
    cv.imshow('frameR', frameR)
    if cv.waitKey(1) == ord('q'):
        break

# Release everything if job is finished
capL.release()
capR.release()
outL.release()
outR.release()
cv.destroyAllWindows()
</code></pre>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  Após a captura dos vídeos, o script abaixo foi executado para gerar o vídeo em 3D:
</p>

<pre><code class="language-python">
criar video 3d:

import numpy as np 
import cv2


CamL_id = "data_you/stereoL.mp4"
CamR_id = "data_you/stereoR.mp4"

CamL= cv2.VideoCapture(CamL_id)
CamR= cv2.VideoCapture(CamR_id)

print("Reading parameters ......")
cv_file = cv2.FileStorage("data_you/params_py.xml", cv2.FILE_STORAGE_READ)

Left_Stereo_Map_x = cv_file.getNode("Left_Stereo_Map_x").mat()
Left_Stereo_Map_y = cv_file.getNode("Left_Stereo_Map_y").mat()
Right_Stereo_Map_x = cv_file.getNode("Right_Stereo_Map_x").mat()
Right_Stereo_Map_y = cv_file.getNode("Right_Stereo_Map_y").mat()
cv_file.release()

print("Starting while ......")

fourcc = cv2.VideoWriter_fourcc(*'XVID')
fps = 20.0
out = cv2.VideoWriter('movie3d_1.avi', fourcc, fps, (700, 700))


while True:
	retR, imgR= CamR.read()
	retL, imgL= CamL.read()
	
	if retL and retR:
		imgR_gray = cv2.cvtColor(imgR,cv2.COLOR_BGR2GRAY)
		imgL_gray = cv2.cvtColor(imgL,cv2.COLOR_BGR2GRAY)

		Left_nice= cv2.remap(imgL,Left_Stereo_Map_x,Left_Stereo_Map_y, cv2.INTER_LANCZOS4, cv2.BORDER_CONSTANT, 0)
		Right_nice= cv2.remap(imgR,Right_Stereo_Map_x,Right_Stereo_Map_y, cv2.INTER_LANCZOS4, cv2.BORDER_CONSTANT, 0)

		output = Right_nice.copy()
		output[:,:,0] = Right_nice[:,:,0]
		output[:,:,1] = Right_nice[:,:,1]
		output[:,:,2] = Left_nice[:,:,2]

		# output = Left_nice+Right_nice
		output = cv2.resize(output,(700,700))
		cv2.namedWindow("3D movie",cv2.WINDOW_NORMAL)
		cv2.resizeWindow("3D movie",700,700)
		out.write(output)
		cv2.imshow("3D movie",output)

		cv2.waitKey(1)
	
	else:
		break

out.release()
cv2.destroyAllWindows()
</code></pre>
 
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  Os resultados da execução dos dois scripts acima são apresentados na sessão <strong>"Análise dos Resultados"</strong>.
</p>


<h2 id="analise-dos-resultados">Análise dos Resultados</h2>

<h3 id="-parte-3">PARTE 3 - Calibração de uma câmera estereoscópica e geração de imagem 3D.</h3>

<h3 id="-b-leitura-de-v-deo-em-arquivo">(B) Resultados do exemplo com as imagens fornecidas.</h3>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
Abaixo são apresentadas as imagens processadas pelo programa <strong>calibrate.py</strong> mostrado na "Parte 3/B".
</p>

<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/img1L.png" alt="letf01" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/img1R.png" alt="right01" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/img2L.png" alt="letf02" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/img2R.png" alt="right02" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/img3L.png" alt="letf03" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/img3R.png" alt="right03" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/img4L.png" alt="letf04" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/img4R.png" alt="right04" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/img5L.png" alt="left05" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/img5R.png" alt="right05" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/img5L.png" alt="left06" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/img5R.png" alt="right06" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/img6L.png" alt="letf07" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/img6R.png" alt="right07" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/img7L.png" alt="left08" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/img7R.png" alt="right08" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/img8L.png" alt="letf09" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/img8R.png" alt="right09" width="400" height="200">
</div>

<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/img9L.png" alt="letf10" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/img9R.png" alt="right10" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/img10L.png" alt="letf11" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/img10R.png" alt="right11" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/img11L.png" alt="letf12" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/img11R.png" alt="right12" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/img12L.png" alt="letf13" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/img12R.png" alt="right13" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/img13L.png" alt="letf14" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/img13R.png" alt="right14" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/img14L.png" alt="left15" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/img14R.png" alt="right15" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/img15L.png" alt="left16" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/img15R.png" alt="right16" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/img16L.png" alt="letf17" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/img16R.png" alt="right17" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/img17L.png" alt="left18" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/img17R.png" alt="right18" width="400" height="200">
</div>


<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/img18L.png" alt="letf19" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/img18R.png" alt="right19" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/img19L.png" alt="letf20" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/img19R.png" alt="right20" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/img20L.png" alt="letf21" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/img20R.png" alt="right21" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/img21L.png" alt="letf22" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/img21R.png" alt="right22" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/img22L.png" alt="left23" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/img22R.png" alt="right23" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/img23L.png" alt="left24" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/img23R.png" alt="right24" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/img24L.png" alt="letf25" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/img24R.png" alt="right25" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/img25L.png" alt="left26" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/img25R.png" alt="right26" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_B/img26L.png" alt="letf27" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_B/img26R.png" alt="right27" width="400" height="200">
</div>
<div style="display: flex; justify-content: center">
  <figcaption>Figura 1 - Resultado da calibração através das imagens fornecidas.</figcaption>
</div>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  Os vídeos a seguir foram fornecidos para aplicação do script <strong>movie3d.py</strong> que gera um vídeo em 3D:
</p>

<figure style="text-align: center;">
<video width="640" height="480" controls autoplay loop muted>
  <source src="Resultado_Parte_3_B/stereoL2.mp4" type="video/mp4">
</video>
<figcaption>Câmera lado esquerdo</figcaption>
</figure>
<figure style="text-align: center;">
<video width="640" height="480" controls autoplay loop muted>
  <source src="Resultado_Parte_3_B/stereoR2.mp4" type="video/mp4">
</video>
<figcaption>Câmera lado direito</figcaption>
</figure>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  O script <strong>movie3d.py</strong> utiliza os parâmetros calculados para gerar o mapa de disparidades através das imagens estéreo geradas através das configurações de câmera estéreo. Uma imagem anáglifa para cada par de imagens estéreo é gerada e em seguida, são salvas todas as imagens anáglifas consecutivas como um vídeo. 
</p>

<figure style="text-align: center;">
<video width="640" height="480" controls autoplay loop muted>
  <source src="Resultado_Parte_3_B/parteB.mp4" type="video/mp4">
</video>
<figcaption>Figura xx - Vídeo 3D gerado a partir da exibição consecutiva de imagens anáglifas.</figcaption>
</figure>

<h3>Parâmetros Necessários para a Câmera Estéreo</h3>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
A calibração de uma câmera estéreo envolve determinar um conjunto de parâmetros que descrevem tanto as características internas de cada câmera quanto a relação geométrica entre elas. Esses parâmetros são essenciais para corrigir distorções e possibilitar a reconstrução 3D a partir das imagens capturadas. São mostrados as seguir os todos os parâmetros envolvidos em cada etapa do processo de calibração stereo.</p>

<h3>1. ETAPA 1 - Calibração das câmeras individuais</h3>
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
As duas câmeras são calibradas a partir das imagens do tabuleiro e os seguintes parâmetros são obtidos:</p>
<ul>
  <li><strong>Vetor de erro médio de reprojeção (retL,retR):</strong> Mede o quão bem os pontos projetados a partir do modelo calibrado coincidem com os pontos detectados na imagem, quanto menor, melhor.
  <li><strong>Matrizes intrínsecas (mtxL, mtxR):</strong> Matriz 3×3 que inclui a distância focal (fx, fy) e o centro óptico (cx, cy).</li>
  <li><strong>Coeficientes de Distorção (distL, distR):</strong> Vetor com cinco ou mais coeficientes que modelam a distorção radial e tangencial da lente (k1, k2, p1, p2, k3...).</li>
  <li><strong>Vetores de rotação (distL, distR):</strong> Representam a relação de rotação entre o do sistemas de coordenadas do mundo e o sistema de coordenadas da câmera para cada imagem utilizada na calibração.</li>
  <li><strong>Vetores de rotação (distL, distR):</strong> Representam a relação de translação entre o do sistemas de coordenadas do mundo e o sistema de coordenadas da câmera para cada imagem utilizada na calibração.</li>
</ul>
</p>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  A partir dos parâmetros calculados, da quantidade de pixels na horizontal e na vertical e do método <strong>cv2.getOptimalNewCameraMatrix</strong>, calcula‑se uma nova matriz intrínseca após a correção da distorção, considerando o tamanho da imagem e um fator de zoom que ajusta o campo de visão. Além disso, obtém‑se uma região de interesse recomendada (ROI – Region of Interest), no formato (x,y,w,h), que indica um retângulo dentro da imagem corrigida no qual todos os pixels são válidos, sem áreas pretas. Essa ROI permite recortar a imagem final, eliminando as bordas pretas resultantes do processo de correção de distorção.
<ul>
  <li><strong>Novas matrizes intrínsecas (new_mtxL, new_mtxR):</strong> Matriz 3×3 que inclui a distância focal (fx, fy) e o centro óptico (cx, cy).</li>
  <li><strong>Região de interesse (roiL, roiR):</strong> retangulo dentro da imagem não distorcida onde todos os pixel são valídos(sem áreas pretas).</li> 
 </ul>
</p>

<h3>2. ETAPA 2 - Executando a calibração estéreo com parâmetros intrínsecos fixos</h3>
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
Fixam‑se as matrizes intrínsecas das câmeras para calcular apenas a matriz de rotação, a matriz de translação, a matriz essencial e a matriz fundamental. Como o espaço de parâmetros a ser estimado é amplo e ocorrem acúmulos de erros em etapas como a detecção de cantos e a aproximação de pontos para valores inteiros, aumentam‑se as chances de o método iterativo divergir da solução correta. Dessa forma, calculam‑se os parâmetros de cada câmera individualmente e utiliza‑se o método <strong>stereoCalibrate()</strong> apenas para determinar a transformação entre o par de câmeras estéreo, bem como a matriz essencial e a matriz fundamental.
<ul>
  <li><strong>Vetor de erro médio de reprojeção (retS):</strong> Mede o quão bem os pontos projetados a partir do modelo calibrado coincidem com os pontos detectados na imagem, quanto menor, melhor.
  <li><strong>Matriz de rotação (Rot):</strong> Matriz de rotação entre as duas câmeras.</li>
  <li><strong>Matriz de translação (Trns):</strong> Matriz de translação entre as duas câmeras.</li>
  <li><strong>Matriz Fundamental (Fmat):</strong>A matriz fundamental é uma matriz 3×3 que estabelece a relação epipolar entre pontos correspondentes em duas imagens obtidas por câmeras diferentes. Ela opera diretamente nas coordenadas de imagem, sem considerar os parâmetros intrínsecos das câmeras, e expressa a condição geométrica segundo a qual um ponto em uma imagem corresponde a uma linha epipolar na outra. Essa matriz representa, portanto, a geometria projetiva entre os planos de imagem e possibilita determinar, a partir de correspondências de pontos, restrições para o pareamento de feições sem a necessidade prévia de calibração.</li>
  <li><strong>Matriz Essencial (Emat):</strong> A matriz essencial é uma matriz 3×3 que descreve a relação epipolar entre duas vistas, porém no espaço normalizado obtido após a calibração intrínseca das câmeras. Ela incorpora as matrizes de parâmetros internos e, por isso, permite extrair diretamente as informações extrínsecas do sistema estéreo, como a rotação e a translação relativas entre as câmeras.Diferentemente da matriz fundamental, a matriz essencial atua no domínio das coordenadas livres de distorção e possibilita a reconstrução métrica da cena, servindo como elo entre as correspondências de imagem e a geometria tridimensional real do ambiente observado.</li>
</ul>
</p>

<h3>3. ETAPA 3 - Retificação Stereo</h3>
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
Utilizando os parâmetros intrínsecos da câmera, bem como a rotação e a translação entre as câmeras, aplica‑se a retificação estéreo. Esse processo realiza rotações que alinham os dois planos de imagem de modo que ambos passem a estar no mesmo plano. Além das matrizes de rotação, o método <strong>stereoRectify()</strong> também fornece as matrizes de projeção no novo espaço de coordenadas.
<ul>
  <li><strong>Matrizes de rotação de retificação (rect_l, rect_r):</strong> Matrizes de rotação de retificação para a câmera esquerda e para a câmera direita.
  <li><strong>Novas matrizes de projeção (proj_mat_l, proj_mat_r):</strong> Novas matrizes de projeção para a câmera esquerda e para a câmera direita (depois da retificação).</li>
  <li><strong>Matriz de reprojeção 3D (Q):</strong>Matriz de reprojeção em 3D (usada para transformar disparidade em coordenadas 3D). </li>
  <li><strong>Regiões de interesse (roiL, roiR):</strong>Região de interesse válida (x, y, w, h) na imagem esquerda e direita após retificação.</li>
</ul>
</p>

<h3>3. ETAPA 4 - Mapas de disparidade</h3>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
	Calculam‑se os mapeamentos responsáveis por transformar um par de imagens estéreo em um par de imagens retificadas e livres de distorções, armazenando‑os para uso posterior. Esses mapeamentos geram os mapas de remapeamento (mapX e mapY), que são posteriormente utilizados pelo método <strong>cv2.remap()</strong> para efetivamente corrigir as distorções e aplicar a retificação às imagens.
  <ul>
  <li><strong>mapx e mapy:</strong> Dois arrays que dizem, para cada pixel da imagem retificada, de onde buscar o valor na imagem original. <strong>cv2.initUndistortRectifyMap()</strong>, que permitem a correção de distorção e a retificação das imagens.</li>
  </ul>
</p>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  Todos os parâmetros acima são necessários para criação do par de imagens stereo que foram utilizadas para criar um vídeo em 3D. Esses parâmetros são fundamentais para garantir que as imagens estejam geometricamente alinhadas, livres de distorções e preparadas para reconstrução 3D. Com eles, é possível calcular mapas de disparidade e extrair a profundidade das cenas.
</p>

<h3 id="-c-leitura-de-imagem-de-c-mera">(C) Execute a calibração da sua câmera estéreo (contruída com as webcams) pela captura de suas próprias imagens de calibração e imagens de teste:</h3>


<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  Responda: liste todos os parâmetros e valores obtidos para sua câmera estéreo,
colocando-os nas formas de matrizes e vetores. Quais destes parâmetros forma
salvos no arquivo de parâmetros de calibração (xml)?
</p>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  As imagens a seguir foram tiradas com as câmeras no laboratório e utilizadas para calibrar as imagens.
</p>


<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_C/img1L.png" alt="letf01" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_C/img1R.png" alt="right01" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_C/img2L.png" alt="letf02" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_C/img2R.png" alt="right02" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_C/img3L.png" alt="letf01" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_C/img3R.png" alt="right01" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_C/img4L.png" alt="letf02" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_C/img4R.png" alt="right02" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_C/img5L.png" alt="letf01" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_C/img5R.png" alt="right01" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_C/img6L.png" alt="letf02" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_C/img6R.png" alt="right02" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_C/img7L.png" alt="letf01" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_C/img7R.png" alt="right01" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_C/img8L.png" alt="letf02" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_C/img8R.png" alt="right02" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_C/img9L.png" alt="letf01" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_C/img9R.png" alt="right01" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_C/img10L.png" alt="letf02" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_C/img10R.png" alt="right02" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_C/img11L.png" alt="letf01" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_C/img11R.png" alt="right01" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_C/img12L.png" alt="letf02" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_C/img12R.png" alt="right02" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_C/img13L.png" alt="letf01" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_C/img13R.png" alt="right01" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_C/img14L.png" alt="letf02" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_C/img14R.png" alt="right02" width="400" height="200">
</div>

<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_C/img16L.png" alt="letf02" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_C/img16R.png" alt="right02" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_C/img17L.png" alt="letf01" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_C/img17R.png" alt="right01" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab3/Resultado_Parte_3_C/img18L.png" alt="letf02" width="400" height="200">
  <img src="/Lab3/Resultado_Parte_3_C/img18R.png" alt="right02" width="400" height="200">
</div>
<figcaption>Figura xx - Resultados.</figcaption>
</figure>

<h3>Parâmetros Obtidos da Calibração da Câmera Estéreo</h3>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  Durante o processo de calibração das câmeras estéreo, diversos parâmetros foram estimados. Alguns desses foram armazenados no arquivo <code>params_nossas_fotos_py.xml</code>, gerado pelo script de calibração. A seguir, listam-se os parâmetros obtidos e que foram salvos no arquivo xml. Exibir o conteúdo do arquivo xml se torna inviavél, já que se trata de um arquivo com mais de dez mil linhas, porém, o arquivo se encontrar no repositório do github.
</p>

<h3>1. Parâmetros Salvos no Arquivo XML</h3>
<ul>
  <li><strong>Left_Stereo_Map_x</strong> – mapa de remapeamento no eixo X da câmera esquerda.</li>
  <li><strong>Left_Stereo_Map_y</strong> – mapa de remapeamento no eixo Y da câmera esquerda.</li>
  <li><strong>Right_Stereo_Map_x</strong> – mapa de remapeamento no eixo X da câmera direita.</li>
  <li><strong>Right_Stereo_Map_y</strong> – mapa de remapeamento no eixo Y da câmera direita.</li>
</ul>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  Esses mapas são matrizes que indicam como cada pixel da imagem original deve ser deslocado para corrigir distorções e alinhar as imagens. Eles são gerados pela função <code>cv2.initUndistortRectifyMap()</code> e utilizados posteriormente na função <code>cv2.remap()</code>.
</p>

<h3>2. Listagem dos parâmetros obtidos pela calibração da câmera stereo.</h3>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  A imagem a seguir mostra a modificação feita no script <strong>calibrate_parteC.py</strong>, utilizado para calibração da câmera stereo confeccionada no laboratório. Logo em seguida, o resultado da impressão dos parâmetros pelo programa:
</p>

<div style="style="text-align: center;">
  <img src="/Lab3/Resultado_Parte_3_B/script_mod.jpg" alt="letf02" width="600" height="500">
  <figcaption>
   Figura xx - Ajuste feito para impressão dos parâmetros.
  </figcaption>
</div>


<pre><code class="language-python">
Stereo calibration .....
Matrix Rotação (Rot): 

[[ 0.99121894  0.00674294  0.1320589 ]
 [-0.00530224  0.99992257 -0.01125807]
 [-0.13212458  0.010459    0.99117794]]

Matrix de translação (Trns) : 

[[ 0.81684567]
 [ 0.01282107]
 [-0.22357859]]

Matrix Essencial (Emat): 

[[-0.00287945  0.22369537  0.0101909 ]
 [-0.11368994 -0.01005097 -0.83916495]
 [-0.0170396   0.81669597 -0.01088924]]

Matrix Fundamental (Fmat) : 

[[-3.67878631e-07  2.87749616e-05 -4.80658921e-03]
 [-1.45198494e-05 -1.29243921e-06 -6.88406865e-02]
 [ 1.62833980e-03  6.33606612e-02  1.00000000e+00]]

Matriz de rotação de retificação esquerda (rect_l) : 

[[ 0.99074034  0.0188782  -0.13445146]
 [-0.01972402  0.99979315 -0.00496159]
 [ 0.13432998  0.00756757  0.99090776]]

Matriz de rotação de retificação direita (rect_r) : 

[[ 0.96441237  0.01513725 -0.26396902]
 [-0.0134645   0.99987617  0.00814505]
 [ 0.26405963 -0.00430098  0.96449677]]

Nova matriz de projeção câmera esquerda (proj_mat_l): 

[[683.86057701   0.         484.93750668   0.        ]
 [  0.         683.86057701 201.44730759   0.        ]
 [  0.           0.           1.           0.        ]]

Nova matriz de projeção câmera direita (proj_mat_r): 

[[683.86057701   0.         484.93750668 579.22168168]
 [  0.         683.86057701 201.44730759   0.        ]
 [  0.           0.           1.           0.        ]]

Matriz de reprojeção 3D (Q) : 

[[   1.            0.            0.         -484.93750668]
 [   0.            1.            0.         -201.44730759]
 [   0.            0.            0.          683.86057701]
 [   0.            0.           -1.18065431    0.        ]]
Saving paraeters ......

</code>

<h3>3. Observações</h3>
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  Apesar de todos os parâmetros serem calculados pelo OpenCV durante o processo de calibração e retificação estéreo, apenas os mapas de remapeamento foram efetivamente salvos no arquivo XML no experimento atual. Caso desejado, os demais parâmetros também podem ser salvos com comandos adicionais no script Python, como:
</p>
<pre><code class="language-python">
cv_file.write("mtxL", mtxL)
cv_file.write("distL", distL)
cv_file.write("R", Rot)
cv_file.write("T", Trns)
</code></pre>

<h4>4. Conclusão</h4>
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  Os parâmetros armazenados no XML são essenciais para corrigir a distorção das lentes e alinhar as imagens da câmera estéreo. Já os parâmetros intrínsecos, extrínsecos e de retificação permitem a reconstrução da cena em 3D e podem ser adicionados ao arquivo XML caso seja necessário utilizá-los posteriormente em outros scripts.
</p>

<h3 id="-d-grava-o-de-v-deo-da-c-mera">(D) Realize a gravação de um vídeo 3D com sua câmera estéreo.</h3>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
 Responda: a percepção individual de todos integrantes da equipe. Compare e
analise as diferenças com os resultados ao vivo e gravado.
</p>
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  Primeiramente, foi gravado um vídeo utilizando a câmera estereoscópica (junção de duas câmeras identicas) confeccionada no laboratório e o script abaixo. Estes vídeos são apresentados a seguir. O último vídeo mostra o vídeo 3D com a imagens anáglifas após a calibração das imagens das câmeras.
</p>

<pre><code class="language-python">
Captura de videos:

import numpy as np
import cv2 as cv
import os

# Certifique-se de que o diretório existe
output_dir = os.path.expanduser('~/data_you/')
os.makedirs(output_dir, exist_ok=True)

# Inicializa as câmeras
capL = cv.VideoCapture(0)
capR = cv.VideoCapture(2)

# Verifica se ambas as câmeras foram abertas com sucesso
if not capL.isOpened():
    print("Não foi possível abrir a câmera esquerda (capL)")
    exit()

if not capR.isOpened():
    print("Não foi possível abrir a câmera direita (capR)")
    exit()

# Obtém as propriedades das câmeras (usa a da esquerda como base)
width = int(capL.get(cv.CAP_PROP_FRAME_WIDTH))
height = int(capL.get(cv.CAP_PROP_FRAME_HEIGHT))
fps = 20.0

while True:
    # Captura os frames de ambas as câmeras
    retL, frameL = capL.read()
    retR, frameR = capR.read()

    if not retL or not retR:
        print("Erro ao capturar frames. Encerrando...")
        break


    # Exibe os vídeos em janelas separadas
    cv.imshow('frameL', frameL)
    cv.imshow('frameR', frameR)

    # Sai com 'q'
    if cv.waitKey(1) == ord('q'):
        break

# Libera tudo
#capL.release()
#capR.release()
#cv.destroyAllWindows()

fourcc = cv.VideoWriter_fourcc(*'XVID')
outL = cv.VideoWriter('stereoL.avi', fourcc, fps, (width, height))
outR = cv.VideoWriter('stereoR.avi', fourcc, fps, (width, height))

while capL.isOpened():
    retL, frameL = capL.read()
    retR, frameR = capR.read()
    if not retL:
        print("Can't receive frame (stream end?). Exiting ...")
        break
    # write the flipped frame
    outL.write(frameL)
    outR.write(frameR)
    cv.imshow('frameL', frameL)
    cv.imshow('frameR', frameR)
    if cv.waitKey(1) == ord('q'):
        break

# Release everything if job is finished
capL.release()
capR.release()
outL.release()
outR.release()
cv.destroyAllWindows()
</code>

<figure style="text-align: center;">
<video width="640" height="480" controls autoplay loop muted>
  <source src="Resultado_Parte_3_C/saidaL.mp4" type="video/mp4">
</video>
<figcaption>Câmera lado esquerdo</figcaption>
</figure>
<figure style="text-align: center;">
<video width="640" height="480" controls autoplay loop muted>
  <source src="Resultado_Parte_3_C/saidaR.mp4" type="video/mp4">
</video>
<figcaption>Câmera lado direito</figcaption>
</figure>

<figure style="text-align: center;">
<video width="640" height="480" controls autoplay loop muted>
  <source src="Resultado_Parte_3_C/parteC.mp4" type="video/mp4">
</video>
<figcaption>Vídeo com o efeito 3D</figcaption>
</figure>

<h2>Visão individual Marcos - CFO</h2>
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
 O vídeo passa a sensação de 3D quando objetos se aproximam das câmeras, sendo assim o objetivo foi conluído com sucesso. O sucesso se dá pela calibração das câmerras e a distância correta entre as imagens para aproveitar ao máximo o uso dos óculos. No entando em alguns momentos o efeito 3D é afetado quando objetos aoo fundo são oculpados por apenas uma câmera, mas isso seria um erro de gravação e não programação.
</p>

	
<h2 id="conclus-o">Conclusão</h2>

<h3>Referências</h3>
  <p>
    LEARNOPENCV. Geometry of Image Formation. Disponível em: https://learnopencv.com/geometry-of-image-formation/. Acesso em: 2 jul. 2025.
  </p>
  <p>
    LEARNOPENCV. Camera Calibration using OpenCV. Disponível em: https://learnopencv.com/camera-calibration-using-opencv/. Acesso em: 2 jul. 2025.
  </p>
  <p>
    OPENCV. Camera calibration with OpenCV. Disponível em: https://docs.opencv.org/4.x/dc/dbb/tutorial_py_calibration.html. Acesso em: 2 jul. 2025.
  </p>
</section>
  
