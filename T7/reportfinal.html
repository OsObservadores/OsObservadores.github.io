<head>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>
</head>

<h1 id="relat-rio-laborat-rio-1">ETAPA 7 - Relatório Final do Trabalho (RFT)</h1>
<p>Jorge Luiz Pinto Junior  - RA: 11058715 - CEO</p>
<p>Marcos Baldrigue Andrade - RA: 11201921777 - CFO - Financeiro</p>
<p>Guilherme Eduardo Pereira - RA: 11201720498 - CPO - Desenvolvimento</p>

<h2 id="intro-o">Introdução</h2>
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
</p>
<h3 id="aplicacao">Cenário de Aplicação (CA)</h3>
<h3 id="fundament">Fundamentação Teórica</h3>

<h2 id="materiais-metodos">Materiais e Métodos</h2>

<h3 id="model">Modelagem Funcional do SPV (MF)</h3>

<h3 id="Descr">Descrição da implementação do Sistema de Processamento da Visão (SPV)</h3>

<h4 id="">1. Visão geral do sistema</h4>
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
O sistema implementa um pipeline de monitoramento postural em tempo real para apoio ao “Monitoramento automatizado de indivíduos em situação de vulnerabilidade”. O programa captura vídeo da webcam do laboratório em Ubuntu Linux, corrige a distorção óptica via parâmetros de calibração, estima a pose humana por marcos anatômicos, classifica o estado postural (<em>Em pé</em>, <em>Sentada</em>, <em>Deitada</em> ou <em>Ausente</em>) e emite notificações automáticas via Telegram quando eventos de interesse persistem por um intervalo pré-definido (padrão de 5 segundos). A visualização e os cálculos (ângulos articulares, heurísticas de classificação e lógica temporal) ocorrem <em>on-the-fly</em> sobre o fluxo de vídeo.
</p>

<h2 id="">2. Tecnologias e bibliotecas empregadas</h2>
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
A implementação utiliza a API OpenCV para captura, exibição e correção de distorção; o MediaPipe Pose para detecção e rastreamento de marcos corporais; NumPy e <code>math</code> para cálculos vetoriais e angulares; <code>requests</code> para integração HTTP com o Telegram; e <code>python-dotenv</code> para gestão de credenciais por variáveis de ambiente. Todas as bibliotecas possuem reconhecimento notório, são gratuitas e estão disponíveis para utilização pública.
</p>

<h2 id="">3. Ambiente de execução e operação por usuários leigos</h2>
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
O código é escrito em Python 3 e executa em Ubuntu Linux com acesso a uma webcam padrão. A inicialização ocorre por linha de comando:
</p>

<pre><code class="language-python">

# ====================================================================
# Título do projeto: Monitoramento automatizado de indivíduos em situação de vulnerabilidade
# Nome do programa: posevideo.py
# Exemplo de chamada (Linux): python3 posevideo.py
# Autores:
#  - Jorge Luiz Pinto Junior — RA: 11058715 — CEO
#  - Marcos Baldrigue Andrade — RA: 11201921777 — CFO (Financeiro)
#  - Guilherme Eduardo Pereira — RA: 11201720498 — CPO (Desenvolvimento)
# Data: 2025-07-18
# ====================================================================

import cv2
import time
import mediapipe as mp
import numpy as np
import math
import requests
import os
from dotenv import load_dotenv

load_dotenv()

TOKEN = os.getenv('TELEGRAM_TOKEN')
CHAT_ID = os.getenv('TELEGRAM_CHAT_ID')
MENSAGEM = 'Pessoa observada esta de pé ou saiu do alcance de visão'

# === PARÂMETROS DE CALIBRAÇÃO ===
fs = cv2.FileStorage("calibration.xml", cv2.FILE_STORAGE_READ)
camera_matrix = fs.getNode("camera_matrix").mat()
dist_coeffs = fs.getNode("distortion_coefficients").mat()
fs.release()

def enviar_mensagem(texto):
    url = f'https://api.telegram.org/bot{TOKEN}/sendMessage'
    payload = {
        'chat_id': CHAT_ID,
        'text': texto
    }

    response = requests.post(url, data=payload)
    
    if response.status_code == 200:
        print('✅ Mensagem enviada com sucesso!')
    else:
        print(f'❌ Erro ao enviar mensagem. Código: {response.status_code}')
        print(response.text)

# === Funções de cálculo e classificação ===

def calculate_angle(a, b, c):
    a = np.array(a); b = np.array(b); c = np.array(c)
    ba, bc = a - b, c - b
    ba_norm, bc_norm = np.linalg.norm(ba), np.linalg.norm(bc)
    if ba_norm == 0 or bc_norm == 0:
        return 180.0
    cos_ang = np.dot(ba, bc) / (ba_norm * bc_norm)
    cos_ang = np.clip(cos_ang, -1.0, 1.0)
    return math.degrees(math.acos(cos_ang))

def classify_pose(landmarks):
    xs = [lm.x for lm in landmarks]
    ys = [lm.y for lm in landmarks]
    width, height = max(xs) - min(xs), max(ys) - min(ys)
    if width > height * 1.3:
        return 'Deitada'
    mp_pose = mp.solutions.pose
    left_hip   = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,  landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]
    left_knee  = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]
    left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]
    right_hip   = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,  landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]
    right_knee  = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]
    right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]
    left_angle  = calculate_angle(left_hip, left_knee, left_ankle)
    right_angle = calculate_angle(right_hip, right_knee, right_ankle)
    if (left_angle + right_angle) / 2.0 < 160:
        return 'Sentada'
    return 'Em pé'

# === Loop principal com monitoramento de tempo ===

def main():
    mp_pose = mp.solutions.pose
    pose = mp_pose.Pose(static_image_mode=False, model_complexity=1, enable_segmentation=False)
    mp_drawing = mp.solutions.drawing_utils

    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        raise RuntimeError('Não foi possível acessar a webcam.')

    em_pe_start = None
    ausente_start = None
    em_pe_alertado = False
    ausente_alertado = False
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                print('Falha ao capturar frame da webcam.')
                break
                
            # === CORRIGE DISTORÇÃO USANDO CALIBRAÇÃO ===
            frame_undistorted = cv2.undistort(frame, camera_matrix, dist_coeffs)
            
            results = pose.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
            annotated = frame.copy()
            label = 'Ausente'
            if results.pose_landmarks:
                mp_drawing.draw_landmarks(
                    annotated, results.pose_landmarks,
                    mp_pose.POSE_CONNECTIONS,
                    landmark_drawing_spec=mp.solutions.drawing_styles.get_default_pose_landmarks_style()
                )
                label = classify_pose(results.pose_landmarks.landmark)

                # Reinicia o estado de ausência
                ausente_start = None
                ausente_alertado = False

                # Detecção de "em pé"
                if label == 'Em pé':
                    if em_pe_start is None:
                        em_pe_start = time.time()
                    elif not em_pe_alertado and (time.time() - em_pe_start) >= 5:
                        enviar_mensagem("Pessoa está em pé por 5 segundos!")
                        em_pe_alertado = True
                else:
                    em_pe_start = None
                    em_pe_alertado = False
            else:
                # Ninguém na imagem
                em_pe_start = None
                em_pe_alertado = False

                if ausente_start is None:
                    ausente_start = time.time()
                elif not ausente_alertado and (time.time() - ausente_start) >= 5:
                    enviar_mensagem("Ninguém detectado na câmera por 5 segundos!")
                    ausente_alertado = True                    
                # sobrepõe o rótulo
            font, pos, scale, thickness = cv2.FONT_HERSHEY_SIMPLEX, (20,30), 1.0, 2
            cv2.putText(annotated, label, pos, font, scale, (0,0,0), thickness+2, cv2.LINE_AA)
            cv2.putText(annotated, label, pos, font, scale, (255,255,255), thickness, cv2.LINE_AA)
            cv2.imshow('Pose Detection (press q to quit)', annotated)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
    finally:
        cap.release()
        cv2.destroyAllWindows()
        pose.close()

if __name__ == '__main__':
    main()

</code></pre>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
Durante a execução, o sistema apresenta uma janela de vídeo com sobreposição gráfica da pose e um rótulo textual do estado detectado, permitindo encerramento por meio da tecla <code>q</code>. A lógica de alertas não exige intervenção técnica: mensagens são disparadas automaticamente quando as condições de persistência são satisfeitas. Recomenda-se, para aderência formal, que o título da janela inclua o nome do programa e o nome da equipe, conforme a diretriz institucional.
</p>

<h2 id="">4. Aquisição e calibração da câmera</h2>
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
No início da execução, o sistema lê os parâmetros de calibração a partir do arquivo <code>calibration.xml</code> com <code>cv2.FileStorage</code>, obtendo a matriz intrínseca (<em>camera matrix</em>) e os coeficientes de distorção. Em cada iteração, o quadro bruto é corrigido por <code>cv2.undistort</code>, o que reduz artefatos geométricos, melhora a precisão dos pontos anatômicos e atende ao requisito de calibração intrínseca.
</p>

<h2 id="">5. Estimativa de pose e sobreposição gráfica</h2>
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
A estimação de pose utiliza o MediaPipe Pose em modo dinâmico (<code>static_image_mode=False</code>), detectando marcos como quadris, joelhos e tornozelos. Quando a pose é identificada, o sistema desenha conexões e pontos sobre o quadro com o estilo padrão da biblioteca, fornecendo explicabilidade visual imediata do rastreamento e facilitando a interpretação por usuários leigos.
</p>

<h2 id="">6. Cálculo on-the-fly e classificação postural</h2>
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
O módulo de cálculo define a função <code>calculate_angle(a, b, c)</code>, que projeta vetores, normaliza, limita o cosseno para robustez numérica e calcula o ângulo em graus via <code>arccos</code>. A classificação postural ocorre por heurísticas executadas a cada quadro:
</p>
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
<strong>(i) Heurística de deitado:</strong> quando a largura do <em>bounding box</em> da pose excede 1,3 vezes a altura, o estado é classificado como “Deitada”.
</p>
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
<strong>(ii) Ângulos de joelho:</strong> calculam-se os ângulos esquerdo e direito (quadril–joelho–tornozelo); média inferior a 160° indica flexão compatível com “Sentada”.
</p>
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
<strong>(iii) Caso remanescente:</strong> estados que não satisfazem as condições anteriores são classificados como “Em pé”.
</p>

<h2 id="">7. Lógica temporal e geração de eventos</h2>
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
A lógica temporal utiliza temporizadores por estado para robustecer decisões e mitigar falsos positivos. Ao detectar “Em pé”, o sistema inicia um cronômetro; se a condição persiste por pelo menos 5 segundos e não há alerta prévio, uma mensagem é enviada ao Telegram. Em ausência de detecção de pose, um temporizador de “Ausente” é iniciado e, mantida a condição por 5 segundos, o sistema emite um alerta de ausência. Os temporizadores são reiniciados quando o estado muda, assegurando consistência temporal.
</p>

<h2 id="">8. Mecanismo de notificação (integração com Telegram)</h2>
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
As credenciais de acesso (<code>TELEGRAM_TOKEN</code> e <code>TELEGRAM_CHAT_ID</code>) são obtidas por variáveis de ambiente, carregadas via <code>python-dotenv</code>. O envio de notificações utiliza requisições HTTP <code>POST</code> por meio da biblioteca <code>requests</code>, com verificação de códigos de retorno e registro de sucesso/erro no console. Esse mecanismo permite coleta e auditoria de resultados em canal externo ao programa.
</p>

<h2 id="">9. Interface e comunicação com o usuário</h2>
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
O sistema exibe o rótulo do estado com contorno escuro e preenchimento claro para legibilidade, além da sobreposição dos marcos anatômicos, fornecendo explicabilidade visual. O encerramento pela tecla <code>q</code> é intuitivo. Para atender plenamente à exigência formal, o título da janela deve incluir o nome do programa e da equipe.
</p>

<h2 id="">10. Conformidade com as diretrizes do edital</h2>
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
A solução utiliza OpenCV, executa em Ubuntu com webcam do laboratório, é produzida pela própria equipe, emprega bibliotecas notórias e gratuitas, realiza cálculos em tempo real sobre o vídeo, adota cabeçalhos padronizados nos arquivos, apresenta (ou permite configurar) o título da janela com programa e equipe, adere ao Contexto e Cenário de Aplicação e possibilita uso por usuários leigos com coleta de resultados via Telegram.
</p>

<h2 id="">11. Coleta de resultados e registro</h2>
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
Os eventos relevantes (persistência de “Em pé” e ausência prolongada) são enviados ao Telegram, funcionando como log externo com data e hora. A janela de vídeo atua como evidência visual em tempo real durante testes e demonstrações, enquanto o histórico do chat pode ser exportado para documentação.
</p>

<h2 id="">12. Limitações e considerações práticas</h2>
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
A presença do arquivo de calibração <code>calibration.xml</code> é necessária, recomendando-se validação de existência e tratamento de erros amigáveis ao usuário. Condições de iluminação desfavoráveis e oclusões podem reduzir a confiabilidade da pose; a lógica temporal mitiga ruído, mas não elimina casos extremos. As heurísticas (relação largura/altura e limiar de 160° nos joelhos) são leves e explicáveis, podendo ser especializadas futuramente com vetores de tronco/quadril, filtragem temporal suave e modelos mais robustos.
</p>

<h2 id="">13. Procedimentos para implantação no laboratório (resumo)</h2>
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
(1) Instalar dependências: <code>pip install opencv-python mediapipe numpy requests python-dotenv</code>. (2) Criar arquivo <code>.env</code> com <code>TELEGRAM_TOKEN</code> e <code>TELEGRAM_CHAT_ID</code>. (3) Disponibilizar <code>calibration.xml</code> gerado previamente. (4) Executar <code>python3 posevideo.py</code>. (5) Verificar janela com título contendo nome do programa e equipe. (6) Conferir mensagens no Telegram ao manter-se “Em pé” por ≥ 5 s ou ao permanecer “Ausente” por ≥ 5 s.
</p>

<h3 id="lista">Lista de arquivos: dos código-fonte, imagens, vídeos, e arquivos auxiliares.</h3>
<h3 id="-parte-1">Escrever uma análise técnica.</h3>
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  sobre o grau de atendimento do sistema desenvolvido em relação ao contexto/cenário escolhido: 
 apresentar medidas ou métricas objetivas (numéricas) e/ou qualitativas,
resultantes do desempenho; análise e conclusões. 
</p>

<h2 id="lab">Laboratório Experimental</h2>
<h3 id="Roteiro">Roteiro do laboratório Experimental</h3>
<h3 id="model">Análise dos Resultados do Teste de Campo TCS</h3>
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  apresentar os resultados
de forma organizada, listando detalhadamente os experimentos realizados e
os critérios de avaliação. Analisar também as médias dos alunos, e as
opiniões subjetivas.
</p>
	
<h2 id="conclus-o">Conclusões</h2>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
Nesta seção a equipe deverá comentar se os objetivos propostos na
introdução e a modelagem do trabalho foram atingidos ou não, baseados nos
exemplos apresentados. Deverá ainda comentar sobre os pontos positivos e
negativos e da implementação.
</p>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
A implementação atende aos requisitos funcionais e acadêmicos do SPV: utiliza OpenCV e bibliotecas reconhecidas, executa em Ubuntu com webcam, realiza cálculos em tempo real fundamentados na pose estimada, oferece visualização explicável e notifica condições críticas coerentes com o cenário de aplicação. Para conformidade formal plena, padroniza-se o cabeçalho dos arquivos e configura-se o título da janela com programa e equipe.
</p>

<h2>Referências Bibliográficas</h2>
  <p>
    OPENCV. Feature Detection and Description. Disponível em: https://docs.opencv.org/4.x/db/d27/tutorial_py_table_of_contents_feature2d.html. Acesso em: 25 jul. 2025.
  </p>
  <p>
    OPENCV. Understanding Features. Disponível em: https://docs.opencv.org/4.x/df/d54/tutorial_py_features_meaning.html. Acesso em: 25 jul. 2025.
  </p>
  <p>
    OPENCV. Harris Corner Detection. Disponível em: https://docs.opencv.org/4.x/dc/d0d/tutorial_py_features_harris.html. Acesso em: 25 jul. 2025.
  </p>
    <p>
    OPENCV. Shi-Tomasi Corner Detector & Good Features to Track. Disponível em: https://docs.opencv.org/4.x/d4/d8c/tutorial_py_shi_tomasi.html. Acesso em: 25 jul. 2025.
  </p>
  <p>
    OPENCV. Introduction to SIFT (Scale-Invariant Feature Transform). Disponível em: https://docs.opencv.org/4.x/da/df5/tutorial_py_sift_intro.html. Acesso em: 25 jul. 2025.
  </p>
  <p>
    OPENCV. Feature Matching + Homography to find Objects. Disponível em: https://docs.opencv.org/4.x/d1/de0/tutorial_py_feature_homography.html. Acesso em: 25 jul. 2025.
  </p>
</section>

<h2>Anexo</h2>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
deverá apresentar os códigos e todos arquivos
</p>
  
