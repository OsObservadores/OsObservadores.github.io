<head>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
  <script>hljs.highlightAll();</script>
</head>

<h1 id="relat-rio-laborat-rio-1">Relatório Laboratório 4 - Mapa de profundidade</h1>
<p>Jorge Luiz Pinto Junior  - RA: 11058715 - CEO</p>
<p>Marcos Baldrigue Andrade - RA: 11201921777 - CFO - Financeiro</p>
<p>Guilherme Eduardo Pereira - RA: 11201720498 - CPO - Desenvolvimento</p>
<p>Data de realização do experimento: 02/07/2025</p>
<p>Data de publicação do relatório: 21/07/2025</p>
<h2 id="objetivo-o">Objetivo</h2>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
O presente experimento tem como objetivo compreender e aplicar os conceitos de visão computacional estéreo, com ênfase na geração e interpretação de mapas de disparidade e profundidade. Busca-se, especificamente, analisar o processo de retificação de imagens capturadas por um sistema de câmeras estéreo e realizar um experimento prático de estimativa da distância de objetos com base no mapa de disparidade. Por meio dessa abordagem, pretende-se demonstrar a viabilidade da utilização de técnicas de estéreo visão para a obtenção de informações tridimensionais do ambiente a partir de imagens bidimensionais.
</p> 

<h2 id="intro-o">Introdução</h2>
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  A percepção de profundidade é uma habilidade fundamental do sistema visual humano, viabilizada pela visão estéreo, que utiliza a diferença entre as imagens captadas por cada olho para inferir a distância dos objetos. Essa capacidade, conhecida como estereopsia, inspira o desenvolvimento de sistemas de visão computacional que buscam reconstruir informações tridimensionais a partir de imagens bidimensionais. No contexto da visão computacional, a geometria epipolar e a triangulação constituem a base teórica para a estimativa de profundidade a partir de pares de imagens estéreo.
</p>
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  Quando um ponto do espaço tridimensional é projetado em uma única imagem, perde-se a informação de profundidade devido à natureza da projeção planar. Para recuperar essa informação, torna-se necessário capturar o mesmo ponto a partir de dois pontos de vista distintos, permitindo a aplicação da triangulação. A correta correspondência entre os pontos nas duas imagens é facilitada pelo uso da geometria epipolar, que restringe a busca do ponto correspondente a uma única linha epipolar na imagem adjacente. Com a calibração das câmeras e o conhecimento da configuração espacial entre elas, é possível aplicar algoritmos de disparidade e gerar mapas de profundidade precisos. A utilização de métodos como o StereoSGBM no OpenCV exemplifica a aplicação prática desses conceitos, permitindo a reconstrução tridimensional densa de cenas reais.
</p>
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
O conceito de mapa de profundidade fundamenta-se na relação inversa entre a disparidade observada e a distância dos objetos capturados por uma câmera estéreo. Quando o sistema processa pares de imagens retificadas, cada pixel gera um valor de disparidade que corresponde ao deslocamento horizontal entre as posições correlatas nas duas imagens. A partir dessa disparidade, calcula-se a profundidade 
Z
Z usando a fórmula clássica 
Z=f×Bd
Z=
d
f×B
	​

, onde 
f
f representa a distância focal em pixels, 
B
B indica a linha base (distância entre as câmeras) e 
d
d é a disparidade 
learnopencv.com
GeeksforGeeks
. Em cenários práticos, como diferenças entre os parâmetros ópticos ou imprecisões na medição da linha base, o valor de profundidade é estimado experimentalmente, determinando-se um coeficiente 
M
M que relaciona profundidade e inverso da disparidade por meio de um ajuste de mínimos quadrados 
learnopencv.com
. Dessa forma, o mapa de disparidade é convertido em um mapa de profundidade, viabilizando a percepção tridimensional do ambiente.
</p>


<h2 id="procedimentos-experimentais">Procedimentos Experimentais</h2>

<h3 id="-parte-1">PARTE 1 - Estudo da teoria.</h3>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
Foram apresentados os seguintes links com o conteúdo a ser estudado para execução do experimento: <strong>Link 1:</strong> <a href="https://learnopencv.com/introduction-to-epipolar-geometry-and-stereo-vision/" target="_blank">
    Estudo da geometria epipolar com duas cameras/imagens
  </a>, <strong>Link 2:</strong> <a href="https://docs.opencv.org/4.x/dd/d53/tutorial_py_depthmap.html target="_blank">
    Estudo da formação do Mapa de Profundidade com Par de Imagens Estéreo
  </a>
 e <strong>Link 3:</strong> <a href="https://learnopencv.com/depth-perception-using-stereo-camera-python-c/" target="_blank">
        Estudo do Mapa de Disparidade com OpenCV com Câmeras
  </a>.
  </p> 

<h3 id="-parte-2">PARTE 2 - Construção de uma câmera estereoscópica simples.</h3>

<h3 id="-a-leitura-de-imagem-em-arquivo">(i) Calibração estéreo e arquivo <strong>params_py.xml</strong></h3>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  Para realização desta etapa, foram fornecidas imagens tiradas de uma câmera estereoscópica (junção de duas câmeras iguais) desconhecida. As imagens para cada câmera foram geradas ao mesmo tempo. E através destas, foram calibradas as duas câmeras (lado direito e lado esquerdo). A seguir são apresentadas as imagens fornecidas, onde a imagem a esquerda provém da primeira câmera e a imagem a direita da segunda câmera.
</p>

<h3 id="-b-leitura-de-v-deo-em-arquivo">(ii) Executar o algoritmo Block Matching do OpenCV, sintonizando seus parâmetros.</h3>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
Neste caso é utilizado o programa “disparity_params_gui.py”. Este programa deverá ser adaptado para leitura do arquivo “params_py.xml”, com os parâmetros de calibração da sua camera estéreo. Ao final do processo, o mapa de disparidade será salvo no arquivo “depth_estmation_params_py.xml”. Este arquivo será utilizado no próximo procedimento.
</p>


<h3 id="-b-leitura-de-v-deo-em-arquivo">(iii) Obter o mapa de profundidade. </h3>
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">

	Neste caso é utilizado o programa “disparity2depth_calib.py”. Este programa deverá ser adaptado para leitura do arquivo “params_py.xml”, com os parâmetros de calibração da sua camera estéreo. Neste caso, será utilizado o mapa de disparidade do arquivo “depth_estmation_params_py.xml”. Este mesmo arquivo xml será atualizado com novos valores, pois será utilizado no próximo procedimento
</p>

<h3 id="-b-leitura-de-v-deo-em-arquivo">(iv)  Realizar medidas de distância seguindo as orientações indicadas na seção “Obstacle avoidance system” . </h3>
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
	Neste caso é utilizado o programa “obstacle_avoidance.py”. Este programa deverá ser adaptado para leitura do arquivo “params_py.xml”, e do arquivo “depth_estmation_params_py.xml”. Utilize pelo menos três objetos distintos.
</p>

<h3 id="-b-leitura-de-v-deo-em-arquivo">(v) As medidas de distância realizadas deverão ser colocadas numa tabela. </h3>
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
	As medidas de distância realizadas deverão ser colocadas numa tabela, e comparadas com a distância real. Calcule o erro, e faça uma análise dos resultados das medições bem como da influencia dos parametros.
</p>
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  Para realização desta etapa, foram fornecidas imagens tiradas de uma câmera estereoscópica (junção de duas câmeras iguais) desconhecida. As imagens para cada câmera foram geradas ao mesmo tempo utilizando o código 'capture_images.py'. E através destas, foram calibradas as duas câmeras (lado direito e lado esquerdo) utilizando o código 'calibrate.py'. A seguir são apresentadas as imagens fornecidas, onde a imagem a esquerda provém da primeira câmera e a imagem a direita da segunda câmera.
</p>

<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab4/data_lab4/data/stereoL/img1.png" alt="letf01" width="400" height="200">
  <img src="/Lab4/data_lab4/data/stereoR/img1.png" alt="right01" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab4/data_lab4/data/stereoL/img2.png" alt="letf01" width="400" height="200">
  <img src="/Lab4/data_lab4/data/stereoR/img2.png" alt="right01" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab4/data_lab4/data/stereoL/img3.png" alt="letf01" width="400" height="200">
  <img src="/Lab4/data_lab4/data/stereoR/img3.png" alt="right01" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab4/data_lab4/data/stereoL/img4.png" alt="letf01" width="400" height="200">
  <img src="/Lab4/data_lab4/data/stereoR/img4.png" alt="right01" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab4/data_lab4/data/stereoL/img5.png" alt="letf01" width="400" height="200">
  <img src="/Lab4/data_lab4/data/stereoR/img5.png" alt="right01" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab4/data_lab4/data/stereoL/img6.png" alt="letf01" width="400" height="200">
  <img src="/Lab4/data_lab4/data/stereoR/img6.png" alt="right01" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab4/data_lab4/data/stereoL/img7.png" alt="letf01" width="400" height="200">
  <img src="/Lab4/data_lab4/data/stereoR/img7.png" alt="right01" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab4/data_lab4/data/stereoL/img8.png" alt="letf01" width="400" height="200">
  <img src="/Lab4/data_lab4/data/stereoR/img8.png" alt="right01" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab4/data_lab4/data/stereoL/img9.png" alt="letf01" width="400" height="200">
  <img src="/Lab4/data_lab4/data/stereoR/img9.png" alt="right01" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab4/data_lab4/data/stereoL/img10.png" alt="letf01" width="400" height="200">
  <img src="/Lab4/data_lab4/data/stereoR/img10.png" alt="right01" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab4/data_lab4/data/stereoL/img11.png" alt="letf01" width="400" height="200">
  <img src="/Lab4/data_lab4/data/stereoR/img11.png" alt="right01" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab4/data_lab4/data/stereoL/img12.png" alt="letf01" width="400" height="200">
  <img src="/Lab4/data_lab4/data/stereoR/img12.png" alt="right01" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab4/data_lab4/data/stereoL/img13.png" alt="letf01" width="400" height="200">
  <img src="/Lab4/data_lab4/data/stereoR/img13.png" alt="right01" width="400" height="200">
</div>
<div style="display: flex; justify-content: center; gap: 5px;">
  <img src="/Lab4/data_lab4/data/stereoL/img14.png" alt="letf01" width="400" height="200">
  <img src="/Lab4/data_lab4/data/stereoR/img14.png" alt="right01" width="400" height="200">
</div>
<div style="display: flex; justify-content: center">
  <figcaption>Figura 1 - Imagens capturadas para calibração.</figcaption>
</div>
  

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
Inicialmente, realiza-se a calibração individual de cada câmera por meio do método de calibração OpenCV. Em seguida, determina-se a transformação entre as duas câmeras configuradas no sistema estéreo. Com os parâmetros obtidos, emprega-se o método <strong>stereoCalibrate</strong> para calcular as transformações necessárias à retificação estéreo. A partir disso, utiliza-se o método <strong>initUndistortRectifyMap</strong> para gerar o mapeamento que corrige distorções e prepara as imagens para retificação. Por fim, aplica-se esse mapeamento às imagens originais, obtendo-se um par estéreo retificado e livre de distorções.
</p>
<h3 id="-b-leitura-de-v-deo-em-arquivo">Método para obter o par de imagens estéreo:</h3>

<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
  O script a seguir realiza a captura das imagens com as duas câmeras. as quatro etapas descritas acima: calibração das câmeras individuais, calibração estéreo com parâmetros intrínsecos fixos, retificação estéreo e por fim o mapeamento que obtém o par de imagens estéreo retificadas e sem distorções.</p>

<pre><code class="language-python">
# Importa bibliotecas necessárias
import numpy as np              # Biblioteca para cálculos numéricos (não usada diretamente aqui)
import cv2                      # OpenCV: biblioteca para processamento de imagem e vídeo
import time                     # Para medir tempo e controlar intervalos

# Exibe instruções para o usuário
print("Checking the right and left camera IDs:")
print("Press (y) if IDs are correct and (n) to swap the IDs")
print("Press enter to start the process >> ")
input()  # Aguarda o usuário pressionar Enter

# Define os IDs das câmeras (pode variar de acordo com o PC)
CamL_id = 0                     # ID da câmera da esquerda
CamR_id = 2                     # ID da câmera da direita

# Inicializa as câmeras
CamL = cv2.VideoCapture(CamL_id)
CamR = cv2.VideoCapture(CamR_id)

# Lê 100 frames de cada câmera (isso ajuda a "aquecer" a câmera)
for i in range(100):
    retL, frameL = CamL.read()
    retR, frameR = CamR.read()

# Mostra os últimos frames capturados para o usuário verificar se as câmeras estão corretas
cv2.imshow('imgL', frameL)  # Imagem da câmera da esquerda
cv2.imshow('imgR', frameR)  # Imagem da câmera da direita

# O bloco abaixo foi comentado, mas serviria para o usuário confirmar ou trocar os IDs das câmeras
# if cv2.waitKey(0) & 0xFF == ord('y'):
#     CamL_id = 2
#     CamR_id = 0
#     print("Camera IDs maintained")
# elif cv2.waitKey(0) & 0xFF == ord('n'):
#     CamL_id = 0
#     CamR_id = 2
#     print("Camera IDs swapped")
# else:
#     print("Wrong input response")
#     exit(-1)

# Libera (fecha) as câmeras
CamR.release()
CamL.release()

# Reabre as câmeras com os IDs definidos anteriormente
CamL = cv2.VideoCapture(CamL_id)
CamR = cv2.VideoCapture(CamR_id)

# Define o caminho para salvar as imagens capturadas
output_path = "./data"

# Inicia um cronômetro
start = time.time()

T = 1000           # Tempo entre capturas, em milissegundos (esse valor será ajustado no loop)
count = 0          # Contador de imagens salvas

# Loop principal
while True:
    # Calcula o tempo restante até a próxima tentativa de salvar uma imagem
    timer = T - int(time.time() - start)

    # Lê um frame de cada câmera
    retR, frameR = CamR.read()
    retL, frameL = CamL.read()

    # Cria uma cópia da imagem da esquerda para mostrar o tempo restante
    img1_temp = frameL.copy()
    cv2.putText(img1_temp, "%r" % timer, (50, 50), 1, 5, (55, 0, 0), 5)

    # Mostra as imagens das duas câmeras na tela
    cv2.imshow('imgR', frameR)
    cv2.imshow('imgL', img1_temp)

    # Converte as imagens para tons de cinza (necessário para detecção de padrão de xadrez)
    grayR = cv2.cvtColor(frameR, cv2.COLOR_BGR2GRAY)
    grayL = cv2.cvtColor(frameL, cv2.COLOR_BGR2GRAY)

    # Procura por um padrão de tabuleiro de xadrez 8x6 nas duas imagens
    retR, cornersR = cv2.findChessboardCorners(grayR, (8, 6), None)
    retL, cornersL = cv2.findChessboardCorners(grayL, (8, 6), None)

    # Se o padrão for encontrado nas duas imagens E o tempo chegar a 0, salva as imagens
    if (retR == True) and (retL == True) and timer <= 0:
        count += 1  # Atualiza o número da imagem
        # Salva a imagem da direita
        cv2.imwrite('./data/stereoR/img%d.png' % count, frameR)
        # Salva a imagem da esquerda
        cv2.imwrite('./data/stereoL/img%d.png' % count, frameL)
        print("Foi")  # Confirma que as imagens foram salvas

    # Se o tempo chegou a 0, reinicia o cronômetro
    if timer <= 0:
        start = time.time()

    # Se a tecla ESC (código 27) for pressionada, sai do loop
    if cv2.waitKey(1) & 0xFF == 27:
        print("Closing the cameras!")
        break

# Após sair do loop, libera as câmeras e fecha todas as janelas
CamR.release()
CamL.release()
cv2.destroyAllWindows()
</code></pre>

	
<h2 id="conclus-o">Conclusão</h2>
<p style="text-align: justify; line-height: 1.5; text-indent: 2em;">
</p>

<h2>Referências</h2>
  <p>
	  LEARNOPENCV. Making a Low-Cost Stereo Camera using OpenCV. Disponível em: https://learnopencv.com/making-a-low-cost-stereo-camera-using-opencv/#creating-a-custom-3d-video. Acesso em: 21 jul. 2025.
  </p>
  <p>
	  LEARNOPENCV. Introduction to Epipolar Geometry and Stereo Vision. Disponível em: https://learnopencv.com/introduction-to-epipolar-geometry-and-stereo-vision/. Acesso em: 21 jul. 2025.
  </p>
  <p>
	  LEARNOPENCV. Understanding Lens Distortion. Disponível em: https://learnopencv.com/understanding-lens-distortion/. Acesso em: 21 jul. 2025.
  </p>
  <p>
	  LEARNOPENCV. Stereo Camera Depth Estimation With OpenCV (Python/C++). Disponível em: https://learnopencv.com/depth-perception-using-stereo-camera-python-c/. Acesso em: 21 jul. 2025.
  </p>
  <p>
	  LEARNOPENCV. Depth Map from Stereo Images. Disponível em: https://docs.opencv.org/4.x/dd/d53/tutorial_py_depthmap.html. Acesso em: 21 jul. 2025.
  </p>
  <p>
	  LOOP, C.; ZHANG, Z. Computing Rectifying Homographies for Stereo Vision. In: IEEE Conference on Computer Vision and Pattern Recognition, 1999.
  </p>
  <p>
	  LEARNOPENCV. Geometry of Image Formation. Disponível em: https://learnopencv.com/geometry-of-image-formation/. Acesso em: 21 jul. 2025.
  </p>
</section>
  
